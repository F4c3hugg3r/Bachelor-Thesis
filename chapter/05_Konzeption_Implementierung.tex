% !TEX root = ../Thesis.tex
%%
%%  Hochschule für Technik und Wirtschaft Berlin --  Abschlussarbeit
%%
%% Kapitel 5 - Tests
%%
%%

\chapter{Konzeption und Implementierung} \label{Implementierung}
In diesem Kapitel wird zuerst das Konzept zur Erfüllung der Anforderungen vorgestellt.
Anschließend wird die konkrete Umsetzung der Komponenten detailliert 
dargelegt und erklärt. Die folgende Beschreibung der Architektur und Implementierung dient gemäß \cref{Methodik} zugleich als Nachweis 
für die Erfüllung der Anforderungen, die durch statische Inspektion verifiziert werden.

% TODO Formatierung 
\section{Konzeptioneller Lösungsansatz}
Um die funktionalen und nicht-funktionalen Anforderungen zu erfüllen, wird im Folgenden darauf eingegangen,
wie dies konzeptionell erreicht werden soll. 

\subsection{Logische Komponenten des Scanners}
Da der Scanner asynchron arbeiten soll und Sende- und Empfangsprozess entkoppelt sind (siehe \cref{req:NF-02}), wird 
die Softwarearchitektur nach dem Producer-Consumer-Pattern entworfen. Der Datenfluss wird dabei als Pipeline betrachtet: 
Die Kommunikation zwischen den Modulen erfolgt über sogenannte Channels. Die jeweilige Komponente erhält Daten über einen Channel, 
verarbeitet diese und schreibt die Ergebnisse in einen anderen Channel, welcher gleichzeitig als Puffer dient, um Lastspitzen auszugleichen. 
Diese Modularisierung ermöglicht es, dass I/O-lastige Operationen (wie das Lesen vom Stdin) die CPU-lastigen 
Operationen (Paketkonstruktion, Checksummenberechnung) nicht blockieren.

Auch bei Kontrollflüssen (z.B. Starten einer Komponente) können einmalig Daten übertragen werden. Datenflüsse hingegen 
stehen für einen mehrfach geschehenden Datenaustausch. 

Die \cref{fig:component_diag} zeigt die logischen Komponenten des Scanners und deren Interaktionen:

% TODO Paketerfassung -> Ergebnisverarbeitung oder so ändern
\begin{figure}[htbp]
	\centering
	\includegraphics[width=\textwidth]{pictures/Komponentendiagramm-SYN-Rust_777.drawio.png}
	\caption{Diagramm logischer Komponenten des Scanners (vereinfacht)}
	\label{fig:component_diag}
\end{figure}

In dem Diagramm ist zu erkennen, das zwischen der Paketemissionierungs-Komponente und der Ergebnisverarbeitungs-Komponente kein 
Datenfluss besteht, sondern lediglich das Signal zum Beenden des Scans ausgetauscht wird. Daran ist das zustandslose Design zu erkennen, 
welches die Anforderung \cref{req:F-04} erfüllt. 

Das Startprogramm erstellt Paketrohlinge und dient der Eingabe, sowie Übergabe der Konfigurationsdaten.
Außerdem startet es das Scannerprogramm. Die Jobverwaltung ist für die Funktionsfähigkeit des Programmes hat hauptsächlich
die Aufgabe, die anderen Komponenten korrekt zu vernetzen und zu starten. Die Paketemissionierung übernimmt die Paketbearbeitung, 
die Durchsatzlimitierung und das Versenden der Pakete. Für die Aufgabe des Empfangens und Auswerten der Antwortpakete sind zum einen ein 
\texttt{eBPF Programm} zuständig, welches im Komponentendiagramm an der \eng{Netzwerkinterface}-Komponente
angesiedelt ist und zum anderen die Ergebnisverarbeitung. Letzteres beinhaltet die Logik zum Empfangen der Daten im \eng{User-Space}, welche 
vom \texttt{XDP}-Programm übermittelt wurden und der darauffolgenden Duplikatsentfernung. 

In der \cref{fig:component_diag} wird der Weg der Pakete durch den Netzwerkkartentreiber und die Trennung der Zuständigkeiten
von \eng{User Space} und Linux-Kernel nicht explizit behandelt. Um nun aber die Funktion des \texttt{eBPF}-Programmes zu verbildlichen,
wird in \cref{fig:kernel_diag} der Datenfluss zwischen Scanner-Programm und Netzwerkkarte verdeutlicht.

% TODO Qdisc als Verb beschreiben wie sende/baue/... erklären
\begin{figure}[htbp]
	\centering
	\includegraphics[width=\textwidth]{pictures/TX_RX_Kernel.drawio.png}
	\caption{Weg der Pakete durch den Linux Kernel (vereinfacht)}
	\label{fig:kernel_diag}
\end{figure}

Das Diagramm zeigt mögliche Pfade, die ein Paket durchläuft, wenn es entweder gesendet oder empfangen wird. Dabei werden auch die unterschiedlichen
XDP-Modi (siehe \cref{Grundlagen.XDP}) beachtet. Im Sendeprozess (von der Anwendung zur Netzwerk-Hardware) wird mithilfe von \texttt{AF\_XDP} der Netzwerk-Stack 
des Kernels je nach \eng{Socket}-Konfiguration (\eng{Copy} oder \eng{Zero-Copy}) vollständig oder zum Großteil übersprungen. Die \texttt{AF\_PACKET}-Variante
hingegen durchläuft immer einige wenige Schritte des regulären Netzwerkstacks. Im Empfangsprozess ist zu sehen, dass das \texttt{eBPF}-Programm 
je nach Modus (\eng{SKB Mode} oder \eng{Driver Mode}) im Treiber der Netzwerkkarte oder direkt zu Beginn des Kernel-Netzwerkstacks ausgeführt wird.
In beiden Fällen werden dort die eingehenden Pakete zuerst untersucht und je nachdem was das Ergebnis der Untersuchung ist, 
direkt verworfen, an den Netzwerkstack weitergeleitet, oder verändert und an den Treiber oder per XDP\_TX direkt an die Netzwerkkarte zum Versenden
zurückgegeben. So werden alle, oder im Falle des \eng{SKB Mode} fast alle, Schritte des regulären Netzwerkstacks eingespart.
Die Ergebnisse der Untersuchung im \texttt{eBPF}-Programm werden bei validen Paketen in eine \texttt{eBPF Map}, 
in diesem Fall einem \texttt{RingBuf} (siehe \cref{ebpf:xdp_program}) geloggt.
Dies hat den Vorteil, dass nur die relevanten Inhalte des Pakets (IP-Adresse, Port) statt des ganzen Paketes übermittelt werden müssen.
Außerdem hat das \eng{User Space}-Programm direkten Zugriff auf den \texttt{RingBuf} und kann die Daten somit ohne Umwege abgreifen.

Auf diese Art und Weise kann der SYN-Scanner die Verarbeitungsschritte sowohl beim Senden als auch beim Empfangen von Paketen auf 
ein Minimum reduzieren, sodass CPU-Zyklen fast ausschließlich für die Anwendungslogik und nicht für das Betriebssystem aufgewendet werden. 
Dies validiert die konsequente Nutzung moderner Kernel-Mechanismen (\cref{req:NF-03}) unter Berücksichtigung der technologischen Einschränkung auf das Linux-Ökosystem (\cref{req:NF-06}) und bringt große Performanzpotenziale mit sich.

\subsection{Performancesteigerne Maßnahmen}
Neben der in \cref{ebpf:xdp_program} gezeigten Kernelumgehung werden zur Maximierung des Durchsatzes (\cref{req:NF-01}) und Minimierung der Ressourcennutzung (\cref{req:NF-05}) 
zwei weitere Maßnahmen verfolgt:

\begin{enumerate}
    \item \textbf{Batching:} Sowohl im Datenaustausch zwischen den Komponenten mithilfe von Channels, als auch beim 
    Versenden von Paketen werden die Daten immer in Batches übertragen. 
    Im Kontext der Channels bedeutet dies, dass statt einzelner Nachrichten Vektoren mit einer Vielzahl von Objekten übermittelt werden. 
    Dies senkt den Synchronisationsaufwand pro Element erheblich, da die Anzahl der Interaktionen mit dem Channel minimiert wird.
    Für das Senden von Paketen reduziert das Batching die Anzahl der Systemaufrufe. 
    Durch die gebündelte Verarbeitung mehrerer Pakete in einem Durchlauf wird der Overhead durch Kontextwechsel zwischen User-Space und Kernel verringert.     
    \item \textbf{Vermeidung von Kopieroperationen und Kontextwechseln:} 
    Zur Reduktion dynamischer Speicherzuweisungen (Allokationen) werden Vektoren, falls möglich, mit einer festen Kapazität initialisiert, 
    um Reallokationen zur Laufzeit zu vermeiden. Bereits verwendete Vektoren werden nicht verworfen, sondern lediglich geleert und wiederverwendet.
    Zudem wurde beim Design auf die Vermeidung von Kopieroperationen geachtet. Das eBPF-Programm (siehe \cref{eBPF}) arbeitet beispielsweise direkt auf Referenzen 
    des Speicherbereichs (\eng{Zero-Copy}), und auch die für das Parsing der IP-Adressen vom Startprogramm zuständige-Komponente nutzt Mechanismen, 
    um Kopieroperationen zu vermeiden (siehe \cref{jobverwaltung:parser}).
\end{enumerate}

\section{Implementierung und Funktionsweise der Komponenten}
Um die Funktionsweise des Programmes im Detail zu erklären, wird zuerst der Projektaufbau erklärt und anschließend 
die einzelnen Quelldateien vorgestellt und Besonderheiten bezüglich Performanz-steigernden oder Ressourcen-sparenden Umsetzungen erläutert.

\subsection{Projektstruktur Basisimplementierung}
Die Verzeichnisse sind nach Aufgabenbereich gegliedert, um eine übersichtliche Gesamtstruktur zu haben und klar zeigen
zu können, welches Verzeichnis für welche Aufgabe zuständig ist. Das Rust-Projekt hat folgende Ordnerstruktur:

\begin{lstlisting}[caption=Ordnerstruktur des SYN-Scanners (gekürzt)]{Projektstruktur Basisimplementierung}
/scanner                                     
    /src
        /bin
            mock_programm.rs
        /scan utils                                    
            /capturing_packets
                bucket.rs
                receiver.rs
            /emitting_packets
                assembler.rs
                rate_limiter.rs
                sender.rs
            /job_controlling
                parser_std_in.rs
                scan_job.rs
            /shared
                helper.rs
                types_and_config.rs
        main.rs
    Cargo.toml
/xdp-common
    /src
        lib.rs
/xdp-ebpf
    /src
        main.rs
...

\end{lstlisting}

In jedem Ordner ist eine \texttt{mod.rs} Datei zu finden, welche hier zugunsten der Lesbarkeit entfernt wurde.
Diese Dateien dienen dazu, ein Verzeichnis als Rust Modul zu definieren und die darin genutzten Dateien für den 
Compiler sichtbar zu machen. Die \texttt{Cargo.toml} ist für die Verwaltung der externen Bibliotheken zuständig.
 
Die Zuordnung der Verzeichnisse zu den logischen Komponenten ist in \cref{fig:component_diag} zu finden.
Die Verzeichnisse \texttt{xdp-ebpf} und \texttt{xdp-common}, welche dort nicht vorkommen,
beschreiben das \texttt{eBPF}-Programm, welches Antwortpakete abfängt, auswertet und nur die relevanten Informationen an den
\eng{User Space} weiterleitet. Das Verzeichnis \texttt{shared} dient lediglich der Steigerung der Übersichtlichkeit. Es enthält
helfende Funktionen, sowie Typenbeschreibungen, die mehrfach im Projekt genutzt werden. Somit ist es für die Funktionalität irrelevant.

\subsection{Übersicht genutzter \eng{Crates}}
Für die Umsetzung der Komponenten sind folgende genutzte \eng{Crates} aufgrund ihres Einflussreichtums hervorzuheben:

% TODO Position mit [H] erzwingen; einheitliche "Nutzung" (entweder allgemein oder spezifisch); \eng{Task} im Allgemeinen zu
% \texttt{} ändern, da in der Programmierung verwendet?
\begin{table}[htbp][H]
\begin{tabularx}{\textwidth}{|c|c|X|}\hline 
\textbf{Crate} & \textbf{Version} & \textbf{Nutzung} \\ \hline
\texttt{tokio} & 1.47.1 & Nutzung für asynchrone Komponenten, Kommunikation über \eng{Channels}, Parsen des \eng{Standard Input} und Starten mehrerer asynchron laufender \eng{Tasks} \\ \hline
\texttt{nix} & 0.30.1 & Erstellen der \texttt{AF\_PACKET}-Schnittstelle und Versenden darüber \\ \hline
\texttt{xdp-socket} & 0.1.4 & Erstellen der \texttt{AF\_XDP}-Schnittstelle und Versenden darüber \\ \hline
\texttt{aya} & 0.13.1 & Stellt Werkzeuge und Strukturen für die Erstellung und Nutzung von \texttt{eBPF}-Programmen zur Verfügung \\ \hline
\texttt{dashmap} & 6.1.0 & Stellt für asynchrone Nutzung optimierte \eng{HashMaps} bereit und führt das \eng{Locking} selbstständig durch \\ \hline
\texttt{pnet} & 0.35.0 & Nutzung als abstrahiertes Netzwerkwerkzeug zur Erstellung der Paket-\eng{Templates} \\ \hline
\texttt{network\_types} & 0.1.0 & Parsen der \eng{Header}-Strukturen aus rohem Speicherbereich, ohne diese zu kopieren \\ \hline
\end{tabularx}
\caption{Genutzte \eng{Crates}}
\label{tab:crates_all}
\end{table}

\subsection{Paketemissionierung (\texttt{emitting\_packets})}
Die Paketemissionierung umfasst den Prozess der Durchsatzlimitierung, der Paketbearbeitung und des Paketversandes inklusive
den dafür benötigten Vorbereitungsschritten.

\subsubsection{\eng{Rate Limiter} (\texttt{rate\_limiter.rs})}
Wie in \cref{fig:emitting_sequence_diag} zu sehen, führt der \eng{Rate Limiter} (\texttt{rate\_limiter.rs}) dem Namen entsprechend
die Funktion der Durchsatzlimitierung (\cref{req:F-08}) aus. Zuerst nimmt er die zu scannenden IP-Adressen vom \eng{Parser} (\texttt{parser\_std\_in})
entgegen, bestimmt die Puffergröße anhand der in dieser Sekunde bereits gesendeten Datenmenge (TODO wahlweise kleinen Flowchart), füllt einen Puffer und erstellt 
für jeden Puffer einen \texttt{tokio} \eng{Task} mit einem \eng{Assembler} (\texttt{assembler.rs}).
Wenn der \eng{Parser} alle IP-Adressen geparst hat, und der \eng{Rate Limiter} alle verarbeitet hat, wird der gleiche Prozess für die restlichen
Zielports durchgeführt, mit dem entscheidenden Unterschied, dass nun auf den internen Puffer an IP-Adressen, welche zuvor gespeichert wurden zugegriffen wird,
was den CPU-Verbrauch potenziell verringert, da die Adressen nun nicht mehr geparst und weitergeleitet werden müssen.

\texttt{tokio} \eng{Tasks} oder auch \eng{Green-Threads} sind kleine Ausführungseinheiten, ähnlich eines Betriebssystem-\eng{Threads}, bloß dass diese 
durch die \texttt{tokio}-eigene Laufzeitumgebung verwaltet werden. Sie sind sehr leichtgewichtig, da sie keine \eng{Context Switches}
benötigen und erlauben asynchrone Ausführung mehrerer \eng{Tasks}, da sie, statt wie Betriebssystem-\eng{Threads} zu blockieren, die Ressourcen
für andere \eng{Tasks} freigeben und somit Nebenläufigkeit ermöglichen \cite{tokio::task_Rust}. Diese Nebenläufigkeit wird hier genutzt, um entsprechend der aktuellen 
Senderate \eng{Assembler} zu erzeugen, die nicht den gesamten Betriebssystem-\eng{Thread} blockieren, wenn die Pakete eines \eng{Assemblers} nicht zuerst 
vom \eng{Sender} entgegengenommen werden. Stattdessen wartet jeder \eng{Assembler}, ohne andere Teile der Software zu beeinträchtigen. So wird sicher gestellt,
dass immer genügend Pakete für den \eng{Sender} bereitstehen. Die Puffergröße eines \eng{Assemblers} wird bei Beginn des Programmes abhängig von der Durchsatzlimitierung
und der \eng{Batch}-Größe rechnerisch ermittelt 
% TODO maybe mathematische Formel ergänzen oder auf checkcurrent_sent_bytes genauer eingehen

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\textwidth]{pictures/Emitting_Sequenz_3.png}
	\caption{Ablaufes und Funktionsweise der \texttt{emitting\_packets}-Komponente (vereinfacht)}
	\label{fig:emitting_sequence_diag}
\end{figure}
% TODO neue Änderungen einfügen (siehe draw.io) + IP Puffer abrufen statt IP Adresse abrufen

\subsubsection{\eng{Assembler} (\texttt{assembler.rs})}
Die Rolle des \eng{Assemblers} ist recht simpel: Jeder \eng{Assembler} iteriert über die ihm verfügbaren IP-Adressen, füllt \eng{Templates} mit 
der Ziel-IP-Adresse, dem Ziel-Port, sowie der \eng{Sequence Number} und berechnet die Checksummen des \eng{IP-} und \eng{TCP-Header} neu. 
Dies dient zur Erfüllung der Anforderung \cref{req:F-01}. Die \eng{Sequence Number} wird wie folgt berechnet:
\begin{equation}
    \text{ISN} = \text{SipHash}_{K}(\texttt{src\_ip}, \texttt{dst\_ip}, \texttt{src\_port}, \texttt{dst\_port})
\end{equation} \label{equ:syn_cookie_umsetzung}

\noindent wobei:
\begin{itemize}
    \itemsep 0pt
    \item \textbf{\text{ISN}:} die berechnete 32-Bit initiale \eng{Sequence Number} (SYN-Cookie).
    \item \textbf{\text{K}:} ein geheimer, zufälliger 128-Bit Schlüssel, der beim Start des Scanners generiert wird.
    \item \textbf{\texttt{src\_ip}, \texttt{dst\_ip}:} die Quell- und Ziel-IP-Adressen der Verbindung.
    \item \textbf{\texttt{src\_port}, \texttt{dst\_port}:} die zugehörigen TCP-Quell- und Ziel-Ports.
\end{itemize}

Die Pseudozufallsfunktion SipHash eignet sich hervorragend, da sie speziell für hohe \eng{Performance} bei kurzen Eingabedaten entwickelt wurde, aber 
einer \textit{Hashing}-Funktion entsprechend bei gleichem Input immer den gleichen Wert zurückgibt \cite{SipHash_a_short_input_PRF_The_Linux_Kernel_documentation}.
Damit dies konsistent funktioniert, muss allerdings ein geheimer Schlüssel genutzt werden, welcher der Paketemissionierungs- sowie der Paketerfassungskomponente bekannt ist.
In den \eng{Templates} sind die restlichen Werte bereits vorhanden. Die Änderungen werden direkt auf Byte-Ebene umgesetzt, da die Feldzuweisungen der 
\eng{Header}-Felder immer gleich sind \cite{Eddy_2022} \cite{Postel_1981}.
Somit können vollständige Pakete in sehr wenigen Schritten und ohne aufwendiges \eng{Parsing} oder gar kompletter Neuerstellung genutzt werden. 
Diese Pakete werden anschließend je nach Konfiguration einzeln oder in \eng{Batches} an den \eng{Sender} weitergeleitet.
% TODO (hier wahlweise flowchart einfügen) 

\subsubsection{\eng{Sender} (\texttt{sender.rs})}
Der \eng{Sender} agiert im Kontrast zu den anderen Subkomponenten in einem eigenen 
Betriebssystem-\eng{Thread}. Das hat den Grund, dass er somit die komplette Kapazität des \eng{Threads} 
alleine ausnutzen kann und bezüglich CPU-Auslastung möglichst wenig mit anderen Prozessen konkurrieren 
soll, um möglichst performant zu sein. Um diesen Effekt zu verstärken wird außerdem der \texttt{core\_affinity}
\eng{Crate} genutzt (siehe \cref{tab:crates_all}). Der Sender läuft in einer ständigen Schleife bis die \eng{Channels} zum Erhalt
der Pakete geschlossen werden. Je nach Konfiguration sendet er \eng{Batches} oder einzelne Pakete über die jeweilige 
Schnittstelle. Die \eng{Socket}-Schnittstelle welche zum Versenden und somit zur
Erfüllung der Anforderung \cref{req:F-02} verwendet wird, wird beim Start des Senders initialisiert.

Der \eng{Sender} kann entweder per \texttt{AF\_PACKET} oder per \texttt{AF\_XDP} senden. 
Dies wurde so implementiert, da es bei der Schaffung einer realistischen Vergleichsbasis 
zwischen den verschiedenen Technologien hilft. Des Weiteren bietet es die Möglichkeit, 
die tatsächliche Notwendigkeit komplexer Technologien zu validieren. 
% TODO wahlweise flowchart für Senden mit xdp / afp einfügen 

\subsection{Ergebnisverarbeitung (\texttt{capturing\_packets})}
In der Ergebnisverarbeitung werden die durch den \texttt{eBPF} vorgeprüften Daten der validen Antworten entgegengenommen und einer
Duplikatsprüfung unterzogen. Anschließend werden die endgültig korrekten Ergebnisse ausgegeben.   

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\textwidth]{pictures/capuring_sequence.drawio.png}
	\caption{Exemplarisches Diagramm zur Funktionsweise der \texttt{capturing\_packets}-Komponente (vereinfacht)}
	\label{fig:capturing_sequence_diag}
\end{figure}
% Batches

\subsubsection{\eng{Receiver} (\texttt{receiver.rs})}
In früheren Iterationen des Programmes lief der \eng{Receiver} ebenso wie der \eng{Sender} in einem eigenen Betriebssystem-\eng{Thread}, um möglichst viel Leistung nutzen
zu können und \eng{Context Switches} zu vermeiden. Die Nutzung von \texttt{pcap} stellte die abstrahierte Netzwerkschnittstelle zur Erfüllung der Anforderung \cref{req:F-03} 
dar. Mit \texttt{pcap} muss sich der Programmierer nicht manuell um \eng{Sockets} oder der Kommunikation mit dem Netzwerk-Stack kümmern. Ein weiterer Vorteil ist die einfache Nutzung
eines \textit{Berkley Packet Filters} (BPF), mit welchem man Pakete an einem frühen Zeitpunkt im Netzwerk-Stack filtern kann. Wenn nun ein Paket empfangen wurde, wurden dessen 
\eng{Header}-Felder mit \texttt{etherparse}, einer Ethernet-\eng{Parsing}-Bibliothek extrahiert und analog zum aktuellen Vorgehen auf Duplikate geprüft. 

Obwohl die Handhabung mit \texttt{pcap} entwicklerfreundlich ist, wurde es letztendlich durch den \texttt{eBPF}-Ansatz ersetzt, da die \eng{Performance} 
in ersten Tests nicht den Ansprüchen dieses Projektes genügte. Dies ist darauf zurückzuführen, dass \texttt{pcap} intern \eng{Raw-Sockets} mit 
\texttt{PF\_PACKET}\footnote{Ist funktional gleich zu AF\_PACKET \cite{socket2_linux_manpage}} nutzt \cite{the-tcpdump-group/libpcap_2026}. 
Die erfordert im Vergleich zu \texttt{AF\_XDP} oder \texttt{eBPF} mehr Schritte im Netzwerk-Stack (siehe \cref{fig:kernel_diag}).

Im aktuellen Ansatz wird der \eng{Receiver} stattdessen in einem \texttt{tokio} \eng{Task} erstellt, um Asynchronität zu gewährleisten. Außerdem dient 
er nun ausschließlich dem Empfang, der durch das \texttt{eBPF}-Programm über den \texttt{RingBuf} geloggten Daten,
der Verwaltung der Duplikaterkennung und der Ausgabe valider Daten. Im ersten Schritt werden Daten aus dem \texttt{RingBuf} abgerufen. 
Da der Zugriff auf den \texttt{RingBuf} über einen Unix-Dateideskriptor erfolgt, dessen Leseoperationen standardmäßig den \eng{Thread} blockieren, 
muss dieser in das asynchrone Modell der Anwendung integriert werden.  Dafür bietet \texttt{tokio} eine Lösung, welche es ermöglicht, 
durchgehend auf neue Pakete zu warten, ohne den ausführenden \eng{Thread} zu blockieren. Anschließend wird die Ziel-IP-Port-Kombination der
Duplikatprüfung, welche im nächsten Absatz genauer beschrieben wird, unterzogen. Sollte es sich um ein Duplikat handeln, werden die Daten verworfen, ansonsten werden sie in den 
\eng{Standard Output} geschrieben. Somit wird Anforderung \cref{req:F-07} erfüllt.

\subsubsection{\eng{Bucket} (\texttt{bucket.rs})}
% Absatz neu strukturieren (dashmaps)
Zur Duplikaterkennung wird ein \textit{Timed Bucket System} genutzt, in welchem mehrere \eng{Buckets} (\eng{HashMaps}) als Zwischenspeicher für 
die bisherigen Antworten dienen. Es kann nur in den derzeit aktiven \eng{Bucket} geschrieben werden, doch aus allen wird gelesen. Nach einer festen Zeiteinheit
wird der nächste \eng{Bucket} aktiv und der am längsten inaktive geleert. Durch die Aufteilung in mehrere \eng{Buckets} sollen starke Auslastungshöhepunkte durch
das Leeren einer sehr aufgeblähten \eng{HashMap} verhindert werden. Außerdem werden dadurch längere \eng{Locking}-Zeiten bei asynchronen Schreib- und Lesezugriffen vermieden.
Die Suche nach Duplikaten gestaltet sich dabei recht schnell, da \eng{HashMaps} eine Suche der Zeitkomplexität $O(1)$ ermöglichen. Um das \eng{Locking} zu verwalten wurde auf 
\eng{DashMaps} aus dem \texttt{dashmap} \eng{Crate} zurückgegriffen, welche für den asynchronen Einsatz optimiert wurden.

Die IP-Adresse und Ziel-Port des Zielsystems der validen Antwort wird entsprechend Anforderung \cref{req:F-07} nach der Duplikatsbereinigung in den 
\eng{Standard Output} geschrieben. Dieser wird vom Mock-Programm (\texttt{mock\_program.rs}) in eine Datei weitergeleitet.

Um die Umsetzung der Anforderung \cref{req:F-06} muss sich nicht explizit gekümmert werden, da der Linux-Netzwerk-Stack bei Erhalt einer Antwort
nach einer gespeicherten Verbindung zu dieser Anfrage sucht, anschließend merkt, dass keine vorhanden ist, da das SYN-Paket über einen \eng{Raw-Socket} verschickt
wurde und automatisch eine \texttt{RST}-Antwort zurückschickt 
%[TODO Quelle? Siehe Linux kernel option net.ipv4.tcp_rst_filter].

\subsection{Programmstart und Jobverwaltung (\texttt{job\_controlling})}
Der Start des Programmes, die Konfiguration sowie das Starten und Verbinden der einzelnen Komponenten geht
von den in dieser Sektion beschriebenen Komponenten aus. Des Weiteren übernehmen diese auch das \eng{Parsing} und
die Weiterleitung der Ziel-IP-Adressen zur \texttt{emitting\_packets}-Komponente.  

\subsubsection{Startprogramm (\texttt{mock\_program.rs})}
Um die Anforderung \cref{req:F-09} zu erfüllen, nimmt der Scanner die IP-Adressen der Ziele über den \eng{Standard Input} entgegen.
Für die Evaluation in dieser Arbeit wurde, um die Vergleichbarkeit herzustellen ein Programm erstellt, welches die Aufgabe des Startens des Scanners, 
die Erstellung der \eng{Ethernet-Templates}, das Schreiben der Daten in den \eng{Standard Input} und das Lesen aus dem \eng{Standard
Output} des Scanners übernimmt. Dort werden auch die Konfigurationsparameter eingetragen. 

Die \eng{Ethernet-Templates}, welche das Fundament zur Erfüllung der Anforderung \cref{req:F-01} darstellen,
werden mithilfe des \texttt{pnet} \eng{Crates} erstellt, da dieser eine entwicklerfreundliche Schnittstelle dafür bereitstellt. 
Dort werden alle Parameter für eine reguläres \texttt{TCP-SYN}-Paket bis auf die Ziel-IP, den Ziel-Port und die \eng{Sequence Number} gesetzt. 
Es wird für jede Quell-IP ein \eng{Template} angelegt, um die Streuung der Paketquellen zur Verschleierung des Scans
und somit die Trefferrate zu erhöhen.

\subsubsection{Einstiegspunkt (\texttt{main.rs})}
Die \texttt{main.rs}-Datei dient als Einstiegspunkt und Startfunktion des SYN-Scanners. Dort wird mithilfe des \texttt{aya} \eng{Crates} das \texttt{eBPF}-Programm 
geladen und die \texttt{eBPF Maps} initialisiert. Des Weiteren werden die Konfigurationsparameter erfasst und letztendlich ein \eng{Scanjob} mit allen 
benötigten Informationen gestartet.

% testen ob das wirklich Vorteile bringt, denn es wird oft auf Zero-Copy geachtet und es gibt nicht super viele Threads (maybe eher durch besseres
% cache handling begründen) <- GANZEN ABSATZ BEI PLATZMANGEL ENTFERNEN
%Eine ressourcensparende Maßnahme ist außerdem die Nutzung eines alternativen \eng{Allocators} \footnote{TODO}, 
%welcher in der \texttt{main.rs}-Datei definiert wird.
%Anstelle des \eng{System Allocators}, welcher ein breites Anwendungsfeld bedient, bietet der \texttt{jemallocator} einen Fokus auf Nebenläufigkeit
%und Skalierbarkeit auf Multiprozessorsystemen \cite{jemalloc}. Das wird dadurch erreicht, dass viermal mehr der sogenannten Arenen als 
%verfügbare Prozessoren erstellt und die \eng{Threads} darunter aufgeteilt werden. \eng{Threads} blockieren sich gegenseitig nur, wenn sie in der gleichen
%Arena sind, was durch die Vielzahl deutlich seltener vorkommt. Außerdem ist die Allokierung von Speicher durch die Nutzung fester \eng{Size Classes}
%für sehr viele kleine Allokationen, wie sie in dem Scanner zum Beispiel bei der Vielzahl an \eng{Batches} von IP-Adressen oder Pakete
%geschieht, effizienter, als die Vorgehensweise des \eng{System Allocators}, welcher die genaue Speichergröße sucht \cite{TODO}.

\subsubsection{\eng{Standard Input Parser} (\texttt{parser\_std\_in})} \label{jobverwaltung:parser}
Der \eng{Parser} parst zum einen die Konfigurationsparameter aus dem \eng{Standard Input} und zum anderen die Ziel-IP-Adressen. 
Um möglichst performant und ressourcensparend vorzugehen, wird im Allgemein ein Fokus auf die Vermeidung neuer 
Allokationen und die Daten, falls möglich, mit \eng{Zero-Copy}-Operationen zu verarbeiten.
Deshalb geschieht das Entgegennehmen, Deserialisieren und Weiterleiten der Adressen in \eng{Batches}.
Dies minimiert unter anderem die Anzahl der \eng{Context Switches} durch die Reduzierung von \eng{System Calls}. 

Der folgende \cref{lst:parser_binary} zeigt das \eng{Parsing} der Daten welche im Binärformat übertragen wurden. 
Um das Verarbeiten unvollständiger IP-Adressen zu vermeiden, wird sich nach jeder Iteration ein \eng{Offset} gemerkt,
sodass keine Daten verloren gehen, falls ein \eng{Batch} nicht vollständig gefüllt oder sauber am Ende einer Adresse endet. 

% TODO (Buffersize erklären (L1 Cache?)) 
\begin{lstlisting}[caption={Binärformat-\eng{Parsing} im \eng{Standard-Input} \eng{Parser}},label=lst:parser_binary]
const BATCH_SIZE: usize = 8192; // 8KB chunks -> 2048 IPv4-Adressen
let mut buffer = [0u8; BATCH_SIZE];
let mut offset = 0;
let mut ip_batch: Vec<[u8; 4]> = Vec::with_capacity(BATCH_SIZE / 4);

loop {
    let read_len = reader.read(&mut buffer[offset..]).await?;
    
    if read_len == 0 { /* EOF handling */ }
    
    let valid_data_len = offset + read_len;
    let mut cursor = 0;
    
    // Verarbeite vollstaendige IP-Pakete
    while cursor + 4 <= valid_data_len {
        let bytes: [u8; 4] = buffer[cursor..cursor + 4].try_into().unwrap();
        cursor += 4;
        
        if bytes == [0, 0, 0, 0] { /* Terminator -> return */ }
        
        ip_batch.push(bytes);
    }
    
    // Sende akkumulierten Batch
    if !ip_batch.is_empty() {
        let batch = std::mem::replace(&mut ip_batch, Vec::with_capacity(BATCH_SIZE / 4));
        sender.send(batch).await?;
    }
    
    // Kopiere fragmentierte Bytes an Puffer-Anfang
    let remaining = valid_data_len - cursor;
    if remaining > 0 {
        buffer.copy_within(cursor..valid_data_len, 0);
    }
    offset = remaining;
}
\end{lstlisting}

Im bereitgestellten Codeauszug wurden explizit die in \cref{tab:parser-optimizations} beschriebenen Performanz-steigernden Maßnahmen umgesetzt.

\begin{table}[htbp]
\begin{tabularx}{\textwidth}{|c|X|}\hline 
\textbf{Maßnahme} & \textbf{Beschreibung} \\ \hline
\texttt{Vec::with\_capacity()} & Der IP-Puffer wird in einen Puffer mit fester Größe gelesen, welcher somit nur einmal allokiert werden muss. \\ \hline
\texttt{std::mem::replace} & Ermöglicht das Tauschen des \texttt{ip\_batch}-Puffers gegen einen neu erstellten, leeren Puffer, ohne dass die Inhalte kopiert werden müssen, da lediglich die \eng{Ownership} gewechselt wird. \\ \hline
Asynchroner \texttt{tokio}-\eng{Reader} & Die Nutzung des asynchronen \texttt{tokio}-\eng{Readers} ermöglicht, dass auch bei vollem \eng{Channel} der \eng{Parser} nie andere Prozesse blockiert. \\ \hline
\end{tabularx}
\caption{Performanz-steigernde Maßnahmen im \eng{Standard-Input} \eng{Parser}}
\label{tab:parser-optimizations}
\end{table}

\subsubsection{\eng{Scanjob} (\texttt{scanjob.rs})}

Ein \eng{Scanjob} beinhaltet alle \eng{User Space}-Komponenten die für den SYN-Scan benötigt werden. Er startet diese und vernetzt sie mithilfe von \texttt{tokio} \eng{Channels}.
Beim Starten der Komponenten werden alle benötigten Informationen übergeben. 

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\textwidth]{pictures/scanjob_seq_1.drawio.png}
	\caption{Funktionsweise der \texttt{scan\_job.rs} Datei (vereinfacht)}
	\label{fig:scanjob_sequence_diag}
\end{figure}

Da das Anheften eines neuen \texttt{XDP}-Programmes einen Neustart des Netzwerkkartentreibers erfordert, wird vor der Erstellung der Sende-\eng{Sockets} eine kurze Zeit 
gewartet. Auch nach dem Starten des \eng{Senders} und des \eng{Receivers} wird kurz gewartet, damit alles auf Abruf ist,
sobald der \eng{Rate Limiter} mit der Produktion der \texttt{SYN}-Pakete beginnt. Dies dient der allgemeinen Stabilität des Programmes.
Wie bereits in den meisten anderen Komponenten wird auch hier \texttt{tokio} zur konkurrenten Ausführung der verschiedenen Programmteile genutzt. Dies 
ermöglicht das unabhängige Handeln der einzelnen Bestandteile, was einerseits der Notwendigkeit des gleichzeitigen Sendens und Empfangens entspringt
und andererseits der \eng{Performance}-Steigerung durch Einsparung von Wartezeiten dient.

\section{\texttt{eBPF}} \label{eBPF}
Der \texttt{eBPF} dient dem Scanner als Empfangspunkt für eingehende Pakete und realisiert die Anforderung an moderne Kernel-Mechanismen (siehe \cref{req:NF-03}). Je nachdem in welchem \texttt{XDP}-Modus das Programm ausgeführt wird, agiert dieses direkt 
im Treiber der Netzwerkkarte oder an der ersten Stelle nach Erstellung eines Puffers im Netzwerkstack. Dadurch können die
Pakete bereits am frühstmöglichen Punkt evaluiert werden, dessen relevante Daten extrahiert und direkt ohne Umweg über den geteilten Speicher der \texttt{eBPF Maps} 
in das \eng{User Space}-Programm übertragen werden (siehe \cref{fig:kernel_diag}). 
Dies führt zu einer massiven Ressourceneinsparung und das wiederum zu einer Zeiteinsparung, da etliche
Zwischenschritte, welche normalerweise durchlaufen werden müssten, um das Paket durch den Netzwerkstack zum \eng{User Space} zu leiten und das Wiederversenden
ohne Kopieraufwand oder \eng{Context Switches} passiert. Durch die \texttt{XDP\_TX}-Funktion können \texttt{RST}-Pakete direkt im \texttt{eBPF}-Programm erstellt und wieder verschickt werden,
sodass der Netzwerkstack sowie \eng{User Space} komplett vermieden werden.  

\subsection{\texttt{XDP}-Programm} \label{ebpf:xdp_program}
Um ein \texttt{eBPF}-Programm nutzen zu können wird es in die \texttt{XDP}-\eng{Hook} des Kernels geladen und zuvor korrekt in \texttt{ELF}-Dateien übersetzt, damit die \texttt{XDP}-\eng{Hook}
das Programm akzeptiert. Das Übersetzen des Rust-Codes übernimmt der \texttt{aya} \eng{Crate} und das Anhängen des Programmes passiert in \texttt{main.rs}, indem die 
durch \texttt{aya} übersetzten Dateien an das genutzte Netzwerkinterface gebunden wird. Auch das Laden der \texttt{eBPF Maps} wird durch \texttt{aya} übernommen und in der \texttt{main.rs}
über die Rust-Schnittstelle dargestellt. Auch wenn immer noch ein gewisses Maß an Komplexität besteht, erleichtert der \eng{Crate} den Implementierungsaufwand
dadurch enorm. Die zum Informationsaustausch zwischen \texttt{eBPF}-Programm und \eng{User Space}-Programm genutzten \texttt{eBPF Maps} werden in \cref{tab:ebpf_maps} aufgeführt.

\begin{table}[htbp]
\begin{tabularx}{\textwidth}{|c|c|X|}\hline 
\textbf{Name} & \textbf{Typ} & \textbf{Nutzung} \\ \hline
\texttt{STATS} & \texttt{PerCpuArray<u64>} & Effiziente, lockfreie Protokollierung von Statistiken pro CPU \cite{Map_Type_“BPF_MAP_TYPE_PERCPU_ARRAY”_-_eBPF_Docs}\\ \hline
\texttt{WHITELIST\_IPV4} & \texttt{HashMap<[u8; 4], u8>} & \eng{HashMap} zum Abgleich der für den Scan genutzten Quell-IP-Adressen \\ \hline
\texttt{EVENTS} & \texttt{RingBuf} & Effizienter, geteilter Puffer-Ring \cite{Map_Type_“BPF_MAP_TYPE_RINGBUF”_-_eBPF_Docs} zur Übermittlung der extrahierten Zielinformationen valider Pakete an den \eng{Receiver} \\ \hline
\texttt{SIPHASH\_KEY} & \texttt{Array<u64>} & Schlüssel zur korrekten Auswertung des \eng{SYN-Cookies} \\ \hline
\end{tabularx}
\caption{Genutzte \texttt{eBPF Maps}}
\label{tab:ebpf_maps}
\end{table}


\subsection{Funktionsweise}

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\textwidth]{pictures/ebpf_component_2.drawio.png}
	\caption{Funktionsweise des \texttt{eBPF}-Programmes (vereinfacht)}
	\label{fig:ebpf_component_diag}
\end{figure}

Wie in \cref{fig:ebpf_component_diag} zu sehen, wird aus allen empfangenen Paketen zuerst der \eng{Ethernet-}, \eng{IP-} und \eng{TCP-Header} extrahiert und 
überprüft. Sollte dabei festgestellt werden, dass ein Paket kein valides \texttt{IPv4-SYN-ACK}-Paket darstellt, wird es per \texttt{XDP\_PASS} an den normalen 
Netzwerkstack des Kernels weitergeleitet. Auch in der anschließenden Prüfung, ob die, da es sich in dem Fall um eine Antwort handelt, Ziel-IP-Adresse
in der \texttt{WHITELIST\_IPV4} vertreten ist oder die Prüfung des \eng{SYN-Cookies} führt bei Fehlschlag zu einem \texttt{XDP\_PASS}. Das bietet den Vorteil, 
dass der reguläre Netzwerkverkehr trotz Nutzung des SYN-Scanners unbeeinträchtigt ist. Um den \eng{SYN-Cookie} zu vergleichen wird die Hash-Berechnung 
mithilfe des \eng{Sip-Hashing}-Algorithmus und des per \texttt{SIPHASH\_KEY} übergegeben Schlüssels durchgeführt. Die vier in \cref{equ:syn_cookie_umsetzung} genannten 
Werte werden wie in \cref{equ:syn_cookie_auswertung} beschrieben verrechnet und ausgewertet, um die Anforderung \cref{req:F-05} 
zu erfüllen.

% TODO möglicherweise mit Quellen belegen müssen und schauen ob teilweise begriffe deutsch sein sollten (wie Memory Allocator)
In dem \texttt{eBPF}-Programm können aus mehreren Gründen keine Funktionen der Standardbibliothek von Rust genutzt werden. Zum Beispiel würden viele Funktionen 
schlichtweg nicht funktionieren, da sie per \eng{System Call} auf Betriebssystemdiensten beruhen die hier nicht verfügbar sind, weil direkt im Kernel 
gearbeitet wird. Dynamische Speicherstrukturen wie \texttt{Vec<T>}, \texttt{String}, oder \eng{HashMap} können nicht genutzt werden, da kein 
Zugriff auf den allgemeinen \eng{System Allocator} besteht. Im Allgemeinen ist der \texttt{eBPF}-\eng{Verifier} sehr restriktiv, weshalb im \texttt{eBPF}-Programm nur
wenige Bibliotheken nutzbar sind. In allen bereits beschriebenen Schritten des \texttt{eBPF}s wurde deshalb mit dem \texttt{network\_types} \eng{Crate} gearbeitet.
Dieser nutzt keine Technologien der Standardbibliothek und erlaubt es, die rohen Speicherbereiche abstrahiert darzustellen und Zeiger auf
die Strukturen der \eng{Header} mit leichter verständlichen \eng{Enums} darzustellen. So können die gewünschten Paketstrukturen gelesen und 
verändert werden, ohne, dass neuer Speicher allokiert werden muss. 

Die Vermeidung neuer Speicherallokation wird unter anderem durch die Nutzung der \texttt{ptr\_at}-Funktion umgesetzt. 
Die \texttt{ptr\_at}-Funktion dient der Navigation durch den per \texttt{ctx} übergebenen Speicherbereich, indem ein \eng{Offset} übergeben und \eng{Pointer} vom Punkt
des \eng{Offsets}, des Endes des Speicherbereichs und die Länge des Bereichs zurückgegeben werden.

% anmerken, dass der Code von aya ist, caption bei code auf Unterseite legen (AI fragens) 
\begin{lstlisting}[caption={\texttt{ptr\_at}-Funktion zum Navigieren durch Speicherbereiche},label=lst:ptr_at]
#[inline(always)]
unsafe fn ptr_at<T>(ctx: &XdpContext, offset: usize) -> Result<*const T, ()> {
    let start = ctx.data();
    let end = ctx.data_end();
    let len = mem::size_of::<T>();
    if start + offset + len > end {
        /* Error handling */
    }
    Ok((start + offset) as *const T)
}
\end{lstlisting}

So wird beispielsweise im folgenden Beispiel der Speicherbereich des \eng{IP-Header} extrahiert, indem der \eng{Offset} eines \eng{Ethernet-Header} (16 Byte)
übergeben wird. 

\begin{lstlisting}[caption={Extraktion des Speicherbereichs des \eng{IP-Header}},label=lst:ptr_at]
    // IPv4 Header
    let ip: *mut Ipv4Hdr = match unsafe { ptr_at_mut(ctx, EthHdr::LEN) } {
        Ok(p) => p,
        Err(_) => {
            /* Error handling */
        }
    };
\end{lstlisting}

Dabei ist zu beachten, dass diese Aufrufe von einem \texttt{unsafe}-Block umschlossen sind. Gemäß \cref{req:NF-04} ist dies zulässig, da der direkte Zugriff auf Kernel-Speicher zwingend notwendig ist und die \texttt{unsafe}-Nutzung auf diese spezifischen Interaktionen beschränkt bleibt. Da dieser Speicher vom Linux-Kernel und nicht von der Rust-Runtime 
verwaltet wird, kann Rust nicht sicherstellen, dass die Rust-typischen Sicherheitsgarantien gewährleistet sind. Diese Entscheidung wurde bewusst 
getroffen, da diese Arbeit performance-orientierte Implementierungen behandelt. 
Durch die besonderen Umstände im Kontext eines \texttt{eBPF}-Programmes mit strengem \eng{Verifier} sind die Sicherheitskonzepte kaum umsetzbar, wenn \eng{Zero-Copy}
angestrebt wird. Dies hängt damit zusammen, dass Rust normalerweise mit einem \texttt{panic!} reagiert, sollte beispielsweise auf einen falschen Index eines
\eng{Slices} (z.B. \texttt{\&[u8]}) zugegriffen werden. Dies ist im Kernel-Kontext nicht erlaubt. Stattdessen bleibt die Möglichkeit eine Kopie des Speicherbereichs
anzufertigen, so wie es beispielsweise der \texttt{etherparse} \eng{Crate} tut, um die Struktur dann in einem sicheren Kontext zu verwalten. Dies mindert aber die 
\eng{Performance} deutlich und ist somit für performanz-orientiere Anwendungen, wie die hier implementierte, nicht die präferierte Lösung. 

Wenn sich ein Paket als valide Antwort herausstellt, werden die Zieldaten über den \texttt{RingBuf} an den \eng{User Space} weitergeleitet. Die Daten werden in der
in \texttt{xdp\_common} definierten Struktur namens \texttt{PacketLog} übertragen, welche die gescannte Adresse und den gescannten Port beinhaltet. Das \texttt{xdp\_common}
Verzeichnis dient lediglich der Definition dieser Struktur und dazugehörigen Getter-Funktionen.

Das anschließende Erstellen und Versenden des \texttt{RST}-Paketes dient einerseits dazu, die Verbindung beim Zielsystem korrekt zu schließen und somit einen 
normalen TCP-Aushandlungsprozess zu simulieren, andererseits hindert es das Zielsystem am Senden weiterer \texttt{SYN-ACK}-Antworten sowie dem Aufrechterhalten
eines Verbindungsstatuses. Um die \eng{Performance} zu erhöhen wird auch hier ein \eng{Zero-Copy}-Ansatz gewählt, indem das ursprüngliche Paket durch das Tauschen
entsprechender Werte und das Neuberechnen einiger Werte umgewandelt wird. Die Veränderungen der Felder sind in \cref{fig:rst_packet_creation} beschrieben.

% urg_ptr und weitere Elemente vergessen
\begin{figure}[h]\label{fig:rst_packet_creation}
    \centering
    % Die resizebox sorgt dafür, dass die Grafik exakt die Seitenbreite nutzt
    \resizebox{\textwidth}{!}{%
    \begin{tikzpicture}[
        font=\sffamily\small,
        % Grundstil für die Speicherblöcke
        packetbyte/.style={
            draw, 
            minimum height=1cm, 
            rectangle, 
            align=center, 
            inner sep=4pt,
            outer sep=0pt
        },
        % Farben für die Header
        eth color/.style={fill=blue!10},
        ip color/.style={fill=green!10},
        tcp color/.style={fill=orange!10},
        data color/.style={fill=gray!20},
        % Stil für vertikale Operations-Pfeile (jetzt schwarz)
        op_arrow/.style={
            ->, 
            thick, 
            color=black, % Farbe geändert auf Schwarz
            >=Stealth,
            shorten >=0pt 
        },
        % Stil für Tausch-Pfeile (gebogen, jetzt schwarz)
        swap_arrow/.style={
            <->, 
            thick, 
            color=black, % Farbe geändert auf Schwarz
            >=Stealth,
            shorten >=0pt,
            shorten <=0pt
        },
        % Beschriftungen über Pfeilen
        arrow_label/.style={
            anchor=south, 
            font=\sffamily\footnotesize\bfseries, 
            inner sep=2pt,
            align=center,
            color=black % Textfarbe Schwarz
        }
    ]

        %% --- REIHE 1: ETHERNET HEADER ---
        \node[packetbyte, eth color, minimum width=4cm] (eth_dst) {Dest MAC};
        \node[packetbyte, eth color, minimum width=4cm, right=0cm of eth_dst] (eth_src) {Source MAC};
        \node[packetbyte, eth color, minimum width=3cm, right=0cm of eth_src] (eth_type) {Type};
        \node[right=0.5cm of eth_type, font=\bfseries\large, anchor=west] {Ethernet Header};

        %% --- REIHE 2: IP HEADER ---
        \node[packetbyte, ip color, minimum width=2cm, below=3.5cm of eth_dst.west, anchor=west] (ip_ver) {Ver/HL};
        \node[packetbyte, ip color, minimum width=2cm, right=0cm of ip_ver] (ip_tos) {TOS};
        \node[packetbyte, ip color, minimum width=3cm, right=0cm of ip_tos] (ip_len) {Total Len};
        \node[packetbyte, ip color, minimum width=4cm, right=0cm of ip_len] (ip_rest) {\dots ID/Frag \dots};
        \node[packetbyte, ip color, minimum width=2.5cm, right=0cm of ip_rest] (ip_chk) {Checksum};
        \node[packetbyte, ip color, minimum width=3cm, right=0cm of ip_chk] (ip_src) {Src IP};
        \node[packetbyte, ip color, minimum width=3cm, right=0cm of ip_src] (ip_dst) {Dest IP};
        \node[right=0.5cm of ip_dst, font=\bfseries\large, anchor=west] {IP Header};

        %% --- REIHE 3: TCP HEADER ---
        \node[packetbyte, tcp color, minimum width=3cm, below=3.5cm of ip_ver.west, anchor=west] (tcp_src) {Src Port};
        \node[packetbyte, tcp color, minimum width=3cm, right=0cm of tcp_src] (tcp_dst) {Dest Port};
        \node[packetbyte, tcp color, minimum width=3.5cm, right=0cm of tcp_dst] (tcp_seq) {Seq Num};
        \node[packetbyte, tcp color, minimum width=3.5cm, right=0cm of tcp_seq] (tcp_ack) {Ack Num};
        \node[packetbyte, tcp color, minimum width=2.5cm, right=0cm of tcp_ack] (tcp_flags) {Flags};
        \node[packetbyte, tcp color, minimum width=2.5cm, right=0cm of tcp_flags] (tcp_chk) {Checksum};
        \node[right=0.5cm of tcp_chk, font=\bfseries\large, anchor=west] {TCP Header};

        %% --- REIHE 4: PAYLOAD / OPTIONS ---
        \node[packetbyte, data color, minimum width=18cm, below=3.5cm of tcp_src.west, anchor=west, dashed] (payload) {TCP Options \& Payload};
        \node[right=0.5cm of payload, font=\bfseries\large, text=gray, anchor=west] {Verworfen};

        %% --- OPERATIONEN ---

        % 1. Ethernet Swap
        \draw[swap_arrow] (eth_src.north) to[bend right=45] node[midway, above, font=\bfseries] {Tausche} (eth_dst.north);

        % 2. IP Address Swap
        \draw[swap_arrow] (ip_src.north) to[bend left=60] node[midway, above, font=\bfseries] {Tausche} (ip_dst.north);

        % 3. Set IP Total Length
        \draw[op_arrow] ($(ip_len.north)+(0,0.8)$) node[arrow_label] {Setze 40 Bytes\\(IP + TCP Header)} -- (ip_len.north);

        % 4. Calc IP Checksum
        \draw[op_arrow] ($(ip_chk.north)+(0,0.8)$) node[arrow_label] {Berechne neu} -- (ip_chk.north);

        % 5. Port Swap
        \draw[swap_arrow] (tcp_src.north) to[bend left=60] node[midway, above, font=\bfseries] {Tausche} (tcp_dst.north);

        % 6. Ack -> Seq (Farbe auf Schwarz geändert)
        \draw[->, thick, color=black, >=Stealth] (tcp_ack.north) to[bend right=65] node[midway, above, font=\bfseries\footnotesize] {Kopiere in Seq Num} (tcp_seq.north);

        % 7. Set RST Flag
        \draw[op_arrow] ($(tcp_flags.north)+(0,0.8)$) node[arrow_label] {Setze RST} -- (tcp_flags.north);

        % 8. Calc TCP Checksum
        \draw[op_arrow] ($(tcp_chk.north)+(0,0.8)$) node[arrow_label] {Berechne neu} -- (tcp_chk.north);

        % 9. Visual Cut (Zentriert im nun größeren Abstand)
        \begin{scope}[shift={($(payload.north) + (0, 1.25)$)}] 
            % Pfeil ist nun normal (nicht gestrichelt) und schwarz
            \draw[->, thick, color=black, >=Stealth] (0, 1.0) -- (0, -1.0);
            
            % Das Kreuz (bleibt rot als Highlight)
            \node[scale=0.8, anchor=center] at (0,0) {
                \tikz{
                    \draw[ultra thick] (-0.3,0.3) -- (0.3,-0.3);
                    \draw[ultra thick] (-0.3,-0.3) -- (0.3,0.3);
                }
            };
            % Text ist nun schwarz
            \node[color=black, right, font=\bfseries] at (0.4,0) {Abschneiden};
        \end{scope}

    \end{tikzpicture}
    }
    \caption{\eng{In-Memory}-Modifikation des \texttt{SYN-ACK}-Paketes zum \texttt{RST}-Paket}
\end{figure}

Das fertige Paket wird anschließend per \texttt{XDP\_TX} direkt in den Puffer der Netzwerkkarte geschrieben und durch die Modifikationen
als valides \texttt{RST}-Paket an den \eng{Sender} der ursprünglichen \texttt{SYN-ACK}-Antwort zurückgeschickt. Dies dient der Erfüllung der Anforderung 
\cref{req:F-06}.

\section{Dokumentation}

% -> Tabelle

% !TEX root = ../Thesis.tex
%%
%%  Hochschule für Technik und Wirtschaft Berlin --  Abschlussarbeit
%%
%% Kapitel 5 - Tests
%%
%%
\chapter{Konzeption und Implementierung} \label{Implementierung}
% TODO nach schreiben des Chapters überarbeiten
In diesem Kapitel wird zuerst das Konzept zur Erfüllung der Anforderungen vorgestellt.
Anschließend wird die konkrete Umsetzung in den beiden Schritten der Basisimplementierung, sowie
im Optimierungsschritt, sowie die Veränderungen, die im Laufe der Entwicklung stattgefunden haben 
dargelegt und erklärt. Daraufhin werden die Schritte zur Qualitätssicherung, welche im Laufe der Entwicklung genutzt 
wurden aufgezeigt und schlussendlich der konkrete Aufbau für die finale Testumgebung beschrieben.

\section{Projektstruktur Basisimplementierung}
Das Rust Projekt hat folgende Ordnerstruktur:

\begin{lstlisting}[caption=Ordnerstruktur des SYN-Scanners (gekürzt)]{Projektstruktur Basisimplementierung}
/scanner                                     
    /src
        /bin
            mock_programm.rs
        /scan utils                                    
            /capturing_packets
                bucket.rs
                receiver.rs
            /emitting_packets
                assembler.rs
                rate_limiter.rs
                sender.rs
            /job_controlling
                parser_std_in.rs
                scan_job.rs
            /shared
                helper.rs
                types_and_config.rs
        main.rs
    cargo.toml
/xdp-common
    /src
        lib.rs
/xdp-ebpf
    /src
        main.rs
...

\end{lstlisting}

In jedem Ordner ist eine \texttt{mod.rs} Datei zu finden, welche hier zugunsten der Lesbarkeit entfernt wurde.
Diese Dateien dienen dazu, ein Verzeichnis als Modul zu definieren und die darin genutzten Dateien für den 
Compiler sichtbar zu machen. Die cargo.toml ist für die Verwaltung der externen Bibliotheken zuständig.

Die Verzeichnisse sind nach Aufgabenbereich gegliedert, um eine übersichtliche Gesamtstruktur zu haben und klar zeigen
zu können, welches Verzeichnis für welche Aufgabe zuständig ist. Inhaltlich relevant sind vor allem \texttt{emitting\_packets},
welches die Paketbearbeitung, das \textit{Rate Limiting} und das Versenden übernimmt. Außerdem
\texttt{mock\_programm.rs}, in welchem die Paketrohlinge erstellt und alle Daten zur Konfiguration eingegeben werden.
Für die Aufgabe des Empfangens und Auswerten der Antowortpakete sind zum einen \texttt{xdp-ebpf}, \texttt{xdp-common} und 
\texttt{capturing\_packets} zuständig. Letzteres beinhaltet die Logik zum Empfangen der Daten im \textit{Userspace}, welche 
vom XDP Programm übermittelt wurden und der darauffolgenden Duplikatsentfernung. Die Verzeichnisse \texttt{xdp-ebpf}, \texttt{xdp-common}
beschreiben das \textit{eBPF} Programm, welches Antwortpakete abfängt, auswertet und nur die relevanten Informationen an den
\textit{Userspace} weiterleitet.
Die Komponente \texttt{job\_controlling} ist für die Funktionsfähigkeit des Programmes auch essenziell, hat aber hauptsächlich
die Aufgabe, die anderen Komponenten korrekt zu vernetzen.

\subsection{Logische Komponenten des Scanners}
Basierend auf dieser Struktur zeigt die Abbildung \ref{fig:component_diag} die logischen Komponenten des \texttt{scanner} Verzeichnisses und deren Interaktionen:
\begin{figure}[htbp]
	\centering
	\includegraphics[width=\textwidth]{pictures/Komponentendiagramm-SYN-Rust_777.drawio.png}
	\caption{Diagramm logischer Komponenten des \texttt{scanner} Verzeichnisses (vereinfacht)}
	\label{fig:component_diag}
\end{figure}
% TODO Paketerfassung -> Ergebnisverarbeitung oder so ändern

Das Verzeichnis \textit{shared} ist dort nicht aufgeführt, da es lediglich der Steigerung der Übersichtlichkeit dient und
helfende Funktionen, sowie Typenbeschreibungen enthält, die mehrfach im Projekt genutzt werden. Somit ist es für die logische Darstellung
irrelevant. Es ist zudem wichtig zu erwähnen, 
dass auch bei Kontrollflüssen (z.B. Starten einer Komponente) einmalig Daten übertragen werden können. Datenflüsse hingegen 
stehen für einen mehrfach geschehenden Datenaustausch. 

In dem Diagramm ist zu erkennen, das zwischen der \texttt{emitting\_packets}-Komponente und der \texttt{capturing\_packets}-Komponente kein 
Datenfluss besteht, sondern lediglich das Signal zum Beenden des Scans ausgetauscht wird. Daran ist das zustandslose Design zu erkennen, 
welches die Anforderung \hyperref[req:F-04]{/F-04/} erfüllt. 

In der Abbildung \ref{fig:component_diag} wird der Weg der Pakete durch den Netzwerkkartentreiber und die Trennung der Zuständigkeiten
von Userspace und Linux Kernel nicht explizit behandelt. Um nun aber die Funktion des \texttt{eBPF} Programmes,
welches in der Projektstruktur unter den Verzeichnissen \texttt{xdp-ebpf} und \texttt{xdp-common} zu finden ist zu verbildlichen,
wird in Abbildung \ref{fig:kernel_diag} der Datenfluss zwischen Scanner Programm und Netzwerkkarte verdeutlicht.

Das Diagramm zeigt mögliche Pfade, die ein Paket durchläuft, wenn es entweder gesendet oder empfangen wird. Dabei werden auch die unterschiedlichen
XDP-Modi (siehe \ref{Grundlagen.XDP}) beachtet. Im Sendeprozess (von der Anwendung zur Netzwerk-Hardware) wird mithilfe von AF\_XDP der Netzwerk-Stack 
des Kernels je nach Socket Konfiguration (copy oder zero-copy) vollständig oder zum Großteil übersprungen. Die AF\_PACKET Variante
hingegen durchläuft immer einige wenige Schritte des regulären Netzwerkstacks. Im Empfangsprozess ist zu sehen, dass das eBPF Programm 
je nach Modus (SKB oder DRV) im Treiber der Netzwerkkarte oder direkt zu Beginn des Kernel-Netzwerkstacks ausgeführt wird.
In beiden Fällen werden dort die eingehenden Pakete zuerst untersucht und je nachdem was das Ergebnis der Untersuchung ist 
direkt verworfen, an den Netzwerkstack weitergeleitet oder verändert und an den Treiber oder direkt an die Netzwerkkarte zum Versenden
zurückgegeben. So werden alle, oder im Falle des SKB-Modus fast alle, Schritte des regulären Netzwerkstacks eingespart.
Die Ergebnisse der Untersuchung im eBPF-Programm werden bei validen Paketen in eine eBPF Map, in diesem Fall einem RingBuf geloggt.
Dies hat den Vorteil, dass nur die relevanten Inhalte des Pakets (IP-Adresse, Port) statt des ganzen Paketes übermittelt werden müssen.
Außerdem hat das Userspace Programm direkten Zugriff auf den RingBuf und kann die Daten somit ohne Umwege abgreifen.

Auf diese Art und Weise kann der SYN-Scanner die Verarbeitungsschritte sowohl beim Senden als auch beim Empfangen von Paketen auf 
ein Minimum reduzieren, was große Performanzchancen mit sich bringt.

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\textwidth]{pictures/TX_RX_Kernel.drawio.png}
	\caption{Weg der Pakete durch den Linux Kernel (vereinfacht)}
	\label{fig:kernel_diag}
\end{figure}

\subsection{Übersicht genutzter Crates}
Für die Umsetzung der Komponenten sind folgende genutzte \textit{Crates} aufgrund ihres Einflussreichtums hervorzuheben:

\begin{table}[htbp]
\caption{Genutzte Crates}
\begin{tabularx}{\textwidth}{|c|c|X|}\hline 
\textbf{Crate} & \textbf{Version} & \textbf{Nutzung} \\ \hline
\textit{tokio} & 1.47.1 & Nutzung für asynchrone Komponenten, Kommunikation über \textit{Channels}, Parsen des Standard-Inputs und Starten mehrerer asynchron laufender Tasks \\ \hline
\textit{nix} & 0.30.1 & Erstellen der \textit{AF\_PACKET} Schnittstelle und Versenden darüber \\ \hline
\textit{xdp-socket} & 0.1.4 & Erstellen der \textit{AF\_XDP} Schnittstelle und Versenden darüber \\ \hline
\textit{aya} & 0.13.1 & Stellt Werkzeuge und Strukturen für die Erstellung und Nutzung von eBPF Programmen zur Verfügung \\ \hline
\textit{dashmap} & 6.1.0 & Stellt für asynchrone Nutzung optimierte \textit{HashMaps} bereit und führt das Lock-Handling selbstständig durch \\ \hline
\textit{pnet} & 0.35.0 & Eine abstrahierte Bibliothek für zahlreiche Anwendungen in der Netzwerkprogrammierung \\ \hline
\textit{network\_types} & 0.1.0 & Parsen der Header Strukturen aus rohem Speicherbereich, ohne diese zu kopieren \\ \hline
\end{tabularx}
\label{tab:crates_all}
\end{table}

\section{Implementierung und Funktionsweise der Komponenten}
Um die Funktionsweise des Programmes im Detail zu erklären, werden im Folgenden die einzelnen Quelldateien vorgestellt und 
Besonderheiten bezüglich performanzsteigernden oder ressourcensparendenden Maßnahmen erläutert. Der Relevanz für das Projekt
des SYN-Scanners entsprechend, werden manche Themen mehr und manche weniger ausführlich behandelt.

\subsection{Paketemissionierung (emitting\_packets)}
Die Paketemissionierung umfasst den Prozess der Durchsatzlimitierung, der Paketbearbeitung und des Paketversandes inklusive
den dafür benötigten Vorbereitungsschritten.

\subsubsection{Rate Limiter (\texttt{rate\_limiter.rs})}
Wie in der Abbildung \ref{fig:emitting_sequence_diag} zu sehen, führt der \textit{Rate Limiter} (\texttt{rate\_limiter.rs}) dem Namen entsprechend
die Funktion der Durchsatzlimitierung (Anforderung \hyperref[req:F-08]{/F-08/}) aus. Zuerst ruft er die zu scannenden IP-Adressen vom \textit{Parser} (\texttt{parser\_std\_in})
entgegen, bestimmt die Puffergröße anhand der in dieser Sekunde bereits gesendeten Datenmenge (TODO wahlweise kleinen Flowchart), füllt einen Puffer und erstellt 
für jeden Puffer einen \textit{tokio task} mit einem \textit{Assembler} (\texttt{assembler.rs}).
Wenn der \textit{Parser} alle IP-Adressen geparst hat, und der \textit{Rate Limiter} alle verarbeitet hat, wird der gleiche Prozess für die restlichen
Zielports durchgeführt, mit dem entscheidenden Unterschied, dass nun auf den internen Puffer an IP-Adressen, welche zuvor gespeichert wurden zugegriffen wird,
was den CPU-Verbrauch potenziell verringert, da die Adressen nun nicht mehr geparst und weitergeleitet werden müssen.

\textit{Tokio tasks} oder auch \textit{Green-Threads} sind kleine Ausführungseinheiten, ähnlich eines Betriebsystem-\textit{Threads}, bloß dass diese 
durch die \textit{tokio}-eigene Laufzeitumgebung verwaltet werden. Sie sind sehr leichtgewichtig, da sie keine Kontext-Wechsel
benötigen und erlauben asynchrone Ausführung mehrerer \textit{tasks}, da sie, statt wie Betriebssystem-\textit{Threads} zu blockieren, die Ressourcen
für andere Tasks freigeben und somit Nebenläufigkeit ermöglichen \cite{tokio::task_Rust}. Diese Nebenläufigkeit wird hier genutzt, um entsprechend der aktuellen 
Senderate \textit{Assembler} zu erzeugen, die nicht den gesamten Betriebssystem-\textit{Thread} blockiert, wenn die Pakete eines Assemblers nicht zuerst 
vom \textit{Sender} entgegengenommen werden. Stattdessen wartet jeder Assembler, ohne andere Teile der Software zu beeinträchtigen. So wird sicher gestellt,
dass immer genügend Pakete für den \textit{Sender} bereitstehen. Die Puffergröße eines Assemblers wird bei Beginn des Programmes abhängig von der Durchsatzlimitierung
und der \textit{Batch}-Größe rechnerisch ermittelt (TODO maybe hierauf genauer eingehen). 

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\textwidth]{pictures/Emitting_Sequenz_3.png}
	\caption{Ablaufes und Funktionsweise der \texttt{emitting\_packets}-Komponente (vereinfacht)}
	\label{fig:emitting_sequence_diag}
\end{figure}
% TODO neue Änderungen einfügen (siehe draw.io) + wahlweise Flow chart oder so für Puffer bestimmen 

\subsubsection{Assembler (\texttt{assembler.rs})}
Die Rolle des \textit{Assemblers} ist recht simpel: Jeder \textit{Assembler} iteriert über die ihm verfügbaren IP-Adressen, füllt \textit{Templates} mit 
der Ziel-IP Adresse, dem Ziel-Port, der \textit{Sequence Number} und berechnet die Checksummen des \textit{IP-} und \textit{TCP-Headers} neu. 
Dies dient zur Erfüllung der Anforderung \hyperref[req:F-01]{/F-01/}. Die \textit{Sequence Number} wird wie folgt berechnet:
\begin{equation}
    \text{ISN} = \text{SipHash}_{K}(\texttt{src\_ip}, \texttt{dst\_ip}, \texttt{src\_port}, \texttt{dst\_port})
\end{equation}

\noindent wobei:
\begin{itemize}
    \itemsep 0pt
    \item \textbf{\text{ISN}:} die berechnete 32-Bit initiale \textit{Sequence Number} (SYN Cookie).
    \item \textbf{\text{K}:} ein geheimer, zufälliger 128-Bit Schlüssel, der beim Start des Scanners generiert wird.
    \item \textbf{\texttt{src\_ip}, \texttt{dst\_ip}:} die Quell- und Ziel-IP-Adressen der Verbindung.
    \item \textbf{\texttt{src\_port}, \texttt{dst\_port}:} die zugehörigen TCP-Quell- und Ziel-Ports.
\end{itemize}

Die Pseudozufallsfunktion \textit{SipHash} eignet sich hervorragend, da sie speziell für hohe Performance bei kurzen Eingabedaten entwickelt wurde aber 
einer \textit{Hashing}-Funktion entsprechend bei gleichem Input immer den gleichen Wert zurückgibt \cite{SipHash_a_short_input_PRF_The_Linux_Kernel_documentation}.
Damit dies konsistent funktioniert, muss allerdings ein geheimer Schlüssel genutzt werden, welcher der Paketemissionierungs- sowie der Paketerfassungskomponente bekannt ist.
In den \textit{Templates} sind die restlichen Werte bereits vorhanden. Die Änderungen werden direkt auf Byte-Ebene umgesetzt, da die Feldzuweisung der 
\textit{Header} immer gleich sind \cite{Eddy_2022,Postel_1981}.
Somit können vollständige Pakete in sehr wenigen Schritten und ohne aufwendiges Parsing oder gar kompletter Neuerstellung genutzt werden. 
Diese Pakete werden anschließend je nach Konfiguration einzeln oder in \textit{Batches} an den Sender weitergeleitet.
% TODO hier wahlweise flowchart einfügen, und wahlweise, dass extra die gleichen Frames bzw. Vecs (mit fester Größe) genommen wurden um mallocs zu sparen 

\subsubsection{Sender (\texttt{sender.rs})}
Der \textit{Sender} agiert im Kontrast zu den anderen Subkomponenten in einem eigenen 
Betriebssystem-\textit{Thread}. Das hat den Grund, dass er somit die komplette Kapazität des \textit{Threads} 
alleine ausnutzen kann und bezüglich CPU-Auslastung möglichst wenig mit anderen Prozessen konkurrieren 
soll, um möglichst performant zu sein. Um diesen Effekt zu verstärken wird außerdem der \texttt{core\_affinity}
\textit{Crate} genutzt (siehe \ref{tab:crates_all}). Der Sender läuft in einer ständigen Schleife bis die Kanäle zum Erhalt
der Pakete geschlossen werden. Je nach Konfiguration sendet er \textit{Batches} oder einzelne Pakete über die jeweilige 
Schnittstelle. Die Socket Schnittstelle welche zum Versenden und somit zur
Erfüllung der Anforderung \hyperref[req:F-02]{/F-02/} verwendet wird, wird beim Start des Senders initialisiert.
% TODO hier wahlweise flowchart für Senden einfügen 

\subsection{Ergebnisverarbeitung (capturing\_packets)}
In der Ergebnisverarbeitung werden die durch den eBPF vorgeprüften Daten der validen Antworten entgegengenommen und einer
Duplikatsprüfung unterzogen. Anschließend werden die endgültig korrekten Ergebnisse ausgegeben.   

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\textwidth]{pictures/capuring_sequence.drawio.png}
	\caption{Exemplarisches Diagramm zur Funktionsweise der \texttt{capturing\_packets}-Komponente (vereinfacht)}
	\label{fig:capturing_sequence_diag}
\end{figure}

\subsubsection{Receiver (\texttt{receiver.rs})}
In früheren Iterationen des Programmes lief der \textit{Receiver} ebenso wie der \textit{Sender} in einem eigenen Betriebssystem-\textit{Thread}, um möglichst viel Leistung nutzen
zu können und Kontext-Wechsel zu vermeiden. Die Nutzung von \textit{pcap} stellte die abstrahierte Netzwerkschnittstelle zur Erfüllung der Anforderung \hyperref[req:F-03]{/F-03/} 
dar. Mit pcap muss sich der Programmierer nicht manuell um \texttt{Sockets} oder der Kommunikation mit dem Netzwerk-Stack kümmern muss. Ein weiterer Vorteil ist die einfache Nutzung
eines \textit{Berkley Packet Filters} (BPF), mit welchem man Pakete an einem frühen Zeitpunkt im Netzwerk-Stack filtern kann. Wenn nun ein Paket empfangen wurde, wurden dessen 
Header-Felder mit \texttt{etherparse}, einer Ethernet-Parsing-Bibliothek extrahiert und analog zum aktuellen Vorgehen auf Duplikate geprüft. 

Obwohl die Handhabung mit pcap entwicklerfreundlich ist, wurde es letztendlich durch den eBPF Ansatz verdrängt, da die Performanz 
in ersten Tests nicht den Ansprüchen dieses Projektes genügte. Dies ist darauf zurückzuführen, dass pcap intern Raw-Sockets mit 
AF\_INET nutzt, welches im Vergleich zu AF\_PACKET oder AF\_XDP deutlich mehr Schritte im Netzwerk-Stack durchlaufen muss (siehe \ref{fig:rx_xdp}),
selbst, wenn durch den BPF irrelevante Pakete hardwarenah herausgefiltert werden.

Im aktuellen Ansatz wird der Receiver stattdessen in einem tokio Task erstellt, um Asynchronität zu gewährleisten. Außerdem dient 
er nun ausschließlich dem Empfang, der durch das eBPF Programm über den RingBuf geloggten Daten,
der Verwaltung der Duplikaterkennung und der Ausgabe valider Daten. Im ersten Schritt werden Daten aus dem RingBuf abgerufen. 
Da der Zugriff auf den RingBuf über einen Unix-Dateideskriptor erfolgt, dessen Leseoperationen standardmäßig den Thread blockieren, 
muss dieser in das asynchrone Modell der Anwendung integriert werden.  Dafür bietet der tokio Crate eine Lösung, welche es ermöglicht, 
durchgehend auf neue Pakete zu warten, ohne den ausführenden Thread zu blockieren. Anschließend wird die Ziel IP-Port Kombination der
Duplikatprüfung, welche im nächsten Absatz genauer beschrieben wird, unterzogen. Sollte es sich um ein Duplikat handeln, werden die Daten verworfen, ansonsten werden sie in den 
Standard Output geschrieben. Somit wird Anforderung \hyperref[req:F-07]{/F-07/} erfüllt.

\subsubsection{Bucket (\texttt{bucket.rs})}
Zur Duplikaterkennung wird ein \textit{Timed Bucket} System genutzt, in welchem mehrere \textit{Buckets} (HashMaps) als Zwischenspeicher für 
die bisherigen Antworten dienen. Es kann nur in den derzeit aktiven Bucket geschrieben werden, doch aus allen wird gelesen. Nach einer festen Zeiteinheit
wird der nächste Bucket aktiv und der am längsten inaktive geleert. Durch die Aufteilung in mehrere Buckets sollen starke Auslastungshöhepunkte durch
das Leeren einer sehr aufgeblähten HashMap verhindert werden. Außerdem werden dadurch längere Locking-Zeiten bei asynchronen Schreib- und Lesezugriffen vermieden.
Die Suche nach Duplikaten gestaltet sich dabei recht schnell, da HashMaps eine Suche der Zeitkomplexität O(1) ermöglichen. Um das Locking zu verwalten wurde auf 
DashMaps aus dem dashmap Crate zurückgegriffen, welche für den asynchronen Einsatz optimiert wurden.

Die IP-Adresse und Ziel-Port des Zielsystems der validen Antwort wird entsprechend Anforderung \hyperref[req:F-07]{/F-07/} nach der Duplikatsbereinigung in den 
\textit{Standard Output} geschrieben. Dieser wird vom Mock Programm (\texttt{mock\_program.rs}) in eine Datei weitergeleitet.

Um die Umsetzung der Anforderung \hyperref[req:F-06]{/F-06/} muss sich nicht explizit gekümmert werden, da der Linux-Netzwerk-Stack bei Erhalt einer Antwort
nach einer gespeicherten Verbindung zu dieser Anfrage sucht, anschließend merkt, dass keine vorhanden ist, da das SYN-Paket über einen Raw-Socket verschickt
wurde und automatisch eine Reset-Antwort zurückschickt [TODO Quelle?].

\subsection{Programmstart und Jobverwaltung (job\_controlling)}
Den Start des Programmes, die Konfiguration sowie das Starten und Verbinden der einzelnen Komponenten geht
von den in dieser Sektion beschriebenen Komponenten aus. Des Weiteren übernehmen diese auch das Parsing und
die Weiterleitung der Ziel-IP-Adressen zur Emitting Komponente.  

\subsubsection{Startprogramm (\texttt{mock\_program.rs})}
Um die Anforderung \hyperref[req:F-09]{/F-09/} zu erfüllen, nimmt der Scanner die IP-Adressen der Ziele über den Standard Input entgegen.
Für die Evaluation in dieser Arbeit wurde, um die Vergleichbarkeit herzustellen ein Programm erstellt, welches die Aufgabe des Startens des Scanners, 
die Erstellung der Ethernet-\textit{Templates}, das Schreiben der Daten in den Standard Input und das Lesen aus dem Standard
Output des Scanners übernimmt. Dort werden auch die Konfigurationsparameter eingetragen. 

Die Ethernet-Templates, welche das Fundament zur Erfüllung der Anforderung \hyperref[req:F-01]{/F-01/} darstellen,
werden mithilfe des pnet Crates erstellt, da dieser eine entwicklerfreundliche Schnittstelle dafür bereitstellt. 
Dort werden alle Parameter für eine reguläres TCP-SYN Paket bis auf die Ziel-IP, den Ziel-Port und die Sequenznumber gesetzt. 
Es wird für jede Quell-IP ein Template angelegt, da diese der Streuung der Paketquellen zur Verschleierung des Scans
und somit der Erhöhung der Trefferrate dienen.

Um möglichst ressourcensparend zu abeiten werden die Ziel-IP-Adressen in Batches, also Ansammlungen von Paketen übertragen.
Dies reduziert die Anzahl der benötigen  Kontext-Wechsel drastisch indem nicht für jede IP-Adresse ein eigener System Call \footnote{TODO} getätigt werden muss.

\subsubsection{Einstiegspunkt (\texttt{main.rs})}
Die main.rs Datei dient als Einstiegspunkt und Startfunktion des SYN-Scanners. Dort wird mithilfe des aya Crates das eBPF Programm 
geladen und die eBPF Maps initialisiert. Des weiteren werden die Konfigurationsparameter erfasst und letztendlich ein Scanjob mit allen 
benötigten Informationen gestartet.

% testen ob das wirklich Vorteile bringt, denn es wird oft auf Zero-Copy geachtet und es gibt nicht super viele Threads (maybe eher durch besseres
% cache handling begründen)
Eine ressourcensparende Maßnahme ist außerdem die Nutzung eines alternativen Allokators \footnote{TODO}, 
welcher in der main.rs Datei definiert wird.
Anstelle des System-Allokators, welcher ein breites Anwendungsfeld bedient, bietet der Jemallocator einen Fokus auf Nebenläufigkeit
und Skalierbarkeit auf Multiprozessorsystemen \cite{jemalloc}. Das wird dadurch erreicht, dass viermal mehr der sogenannten Arenen als 
verfübare Prozessoren erstellt und die Threads darunter aufgeteilt werden. Threads blockieren sich gegenseitig nur, wenn sie in der gleichen
Arena sind, was durch die Vielzahl deutlich seltener vorkommt. Außerdem ist die Allokierung von Speicher durch die Nutzung fester Size Classes
für sehr viele kleine Allokationen, wie sie in dem Scanner zum Beispiel bei der Vielzahl an Batches von IP-Adressen oder Pakete
geschieht, effizienter, als die vorgehensweise des System-Allokators, welcher die genaue Speichergröße sucht \cite{TODO}.

% TODO am besten entfernen 
%\subsubsection{Finish-Broadcaster (\texttt{finish\_broadcaster})}
%Der Finish-Broadcaster dient lediglich dem sauberen Beenden des Programmes. Er ist über Channel mit jeder Userspace Komponente verbunden und
%sendet am Ende des Programmes ein abschließendes Signal um sicher zu gehen, dass alles geschlossen wird. Dies ist lediglich eine Sicherheitsmaßnahme,
%da das Programm mit Adminrechten direkt mit dem Kernel kommuniziert.

\subsubsection{Standard-Input Parser (\texttt{parser\_std\_in})}
Der Parser parst zum einen die Konfigurationsparameter aus dem Standard Input und zum anderen die Ziel IP-Adressen. Das entgegennehmen, deserialisieren
und Weiterleiten der Adressen geschieht in Batches und mit Fokus auf der Vermeidung neuer Allokationen um durch Einsparung von Kopien und Kontext-Wechsel
durch System Calls Ressourcen zu sparen. Dabei wird darauf geachtet die Daten, falls möglich, mit zero-copy Operationen zu verarbeiten. 

Der folgende Codeauszug \ref{lst:parser_binary} zeigt das Parsing der Daten welche im Binärformat übertragen wurden. 
Um das Verarbeiten unvollständiger IP-Adressen zu vermeiden wird sich nach jeder Iteration ein \texttt{offset} gemerkt,
sodass keine Daten verloren gehen, falls ein Batch nicht volständig gefüllt oder sauber am Ende einer Adresse endet. 

% müssen Teile des Codes zum Verständnis erkärt werden wir zB mut?
% TODO Buffersize erklären (L1 Cache?) 
\begin{lstlisting}[caption={Binärformat-Parsing im Standard-Input Parser},label=lst:parser_binary]
const BATCH_SIZE: usize = 8192; // 8KB chunks -> 2048 IPv4-Adressen
let mut buffer = [0u8; BATCH_SIZE];
let mut offset = 0;
let mut ip_batch: Vec<[u8; 4]> = Vec::with_capacity(BATCH_SIZE / 4);

loop {
    let read_len = reader.read(&mut buffer[offset..]).await?;
    
    if read_len == 0 { /* EOF handling */ }
    
    let valid_data_len = offset + read_len;
    let mut cursor = 0;
    
    // Verarbeite vollstaendige IP-Pakete
    while cursor + 4 <= valid_data_len {
        let bytes: [u8; 4] = buffer[cursor..cursor + 4].try_into().unwrap();
        cursor += 4;
        
        if bytes == [0, 0, 0, 0] { /* Terminator -> return */ }
        
        ip_batch.push(bytes);
    }
    
    // Sende akkumulierten Batch
    if !ip_batch.is_empty() {
        let batch = std::mem::replace(&mut ip_batch, Vec::with_capacity(BATCH_SIZE / 4));
        sender.send(batch).await?;
    }
    
    // Kopiere fragmentierte Bytes an Puffer-Anfang
    let remaining = valid_data_len - cursor;
    if remaining > 0 {
        buffer.copy_within(cursor..valid_data_len, 0);
    }
    offset = remaining;
}
\end{lstlisting}

Es wurden explizit folgende Performanz-steigernde Maßnahmen umgesetzt:

\begin{table}[htbp]
\caption{Performanz-steigernde Maßnahmen im Standard-Input Parser}
\begin{tabularx}{\textwidth}{|c|X|}\hline 
\textbf{Maßnahme} & \textbf{Beschreibung} \\ \hline
\texttt{Vec::with\_capacity()} & Der IP-Puffer wird in einen Puffer mit fester Größe gelesen, welcher somit nur einmal allokiert werden muss. \\ \hline
\texttt{std::mem::replace} & Ermöglicht das Tauschen des \texttt{ip\_batch} Puffers gegen einen neu erstellten, leeren Puffer, ohne dass die Inhalte kopiert werden müssen, da lediglich die \textit{Ownership} gewechselt wird. \\ \hline
Asynchroner tokio Reader & Die Nutzung des asynchronen tokio Readers ermöglicht, dass auch bei vollem Channel der Parser nie andere Prozesse blockiert. \\ \hline
\end{tabularx}
\label{tab:parser-optimizations}
\end{table}

\subsubsection{Scanjob (\texttt{scanjob.rs})}

Ein Scanjob beinhaltet alle Userspace Komponenten die für den SYN-Scan benötigt werden. Er startet diese und Vernetzt sie mithilfe von tokio Channels.
Beim Starten der Komponenten werden alle benötigten Informationen übergeben. 

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\textwidth]{pictures/scanjob_seq_1.drawio.png}
	\caption{Funktionsweise der \texttt{scan\_job.rs} Datei (vereinfacht)}
	\label{fig:scanjob_sequence_diag}
\end{figure}

Da das Anheften eines neuen XDP-Programmes einen Neustart des Netzwerkkartentreibers erfordert, wird vor der Erstellung der Sende-Sockets eine kurze Zeit 
gewartet. Auch nach dem Starten des Senders und des Receivers wird kurz gewartet, damit alles auf Abruf ist,
sobald der Rate Limiter mit der Produktion der SYN-Pakete beginnt. Dies dient der Allgemeinen Stabilität des Programmes.
Wie bereits in den meisten anderen Komponenten wird auch hier tokio zur konkurrenten Ausführung der verschiedenen Programmteile genutzt. Dies 
ermöglicht das unabhängige Handeln der einzelnen Bestandteile, was einerseits der Notwendigkeit des gleichzeitigen Sendens und Empfangens entspringt
und andererseits der Performanz-Steigerung durch Einsparung von Wartezeiten dient.

\section{eBPF}
Der eBPF dient dem Scanner als Empfangspunkt für eingehende Pakete. Je nachdem in welchem XDP Modus das Programm ausgeführt wird, agiert dieses direkt 
im Treiber der Netzwerkkarte oder an der ersten Stelle nach Erstellung eines Buffers im Netzwerkstack. Dadurch können die
Pakete bereits am frühstmöglichen Punkt evaluiert werden, dessen relevante Daten extrahiert und direkt ohne Umweg über den geteilten Speicher der eBPF Maps 
in das Userspace Programm übertragen werden (siehe \ref{fig:kernel_diag}). 
Dies führt zu einer massiven Ressourceneinsparung und das wiederum zu einer Zeiteinsparung, da etliche
Zwischenschritte, welche normalerweise durchlaufen werden müssten, um das Paket durch den Netzwerkstack zum Userspace zu leiten und das Wiederversenden
ohne Kopieraufwand oder Context Switches passiert. Durch die XDP\_TX Funktion können RST Pakete direkt im eBPF Programm erstellt und wieder verschickt werden,
sodass der Netzwerkstack sowie Userspace komplett vermieden werden.  

\subsection{XDP Programm}
Um ein eBPF Programm nutzen zu können wird es in die XDP Hook des Kernels geladen und zuvor korrekt in ELF Dateien übersetzt, damit die XDP
Hook das Programm akzeptiert. Das Übersetzen des Rust Codes übernimmt der aya Crate und das Anhängen des Programmes passiert in main.rs, indem die 
durch aya übersetzten Dateien an das genutzte Netzwerkinterface gebunden wird. Auch das Laden der eBPF Maps wird durch aya übernommen und in der main.rs
über die Rust Schnittstelle dargestellt. Auch wenn immernoch ein gewisses Maß an Komplexität besteht, erleichtert der Crate den Implementierungsaufwand
dadurch enorm. Die zum Informationsaustausch zwischen eBPF Programm und Userspace Programm genutzten eBPF Maps werden in \ref{tab:ebpf_maps} aufgeführt.

\begin{table}[htbp]
\caption{Genutzte eBPF Maps}
\begin{tabularx}{\textwidth}{|c|c|X|}\hline 
\textbf{Name} & \textbf{Typ} & \textbf{Nutzung} \\ \hline
\textit{STATS} & \texttt{PerCpuArray<u64>} & Lockfreies Array für jede CPU auf welchen Stats effizient geloggt werden können \cite{Map_Type_“BPF_MAP_TYPE_PERCPU_ARRAY”_-_eBPF_Docs}\\ \hline
\textit{WHITELIST\_IPV4} & \texttt{HashMap<[u8; 4], u8>} & Hashmap zum Abgleich der Quell IP-Adressen, welche für den Scan genutzt werden \\ \hline
\textit{EVENTS} & \texttt{RingBuf} & Ausgabe der extrahierten Zielinformationen valider Pakete an den Receiver mithilfe eines effizienten, über alle CPUs geteilten Puffer Ring \cite{Map_Type_“BPF_MAP_TYPE_RINGBUF”_-_eBPF_Docs}\\ \hline
\textit{SIPHASH\_KEY} & \texttt{Array<u64>} & Der Schlüssel wird benötigt, um den SYN-Cookie korrekt auszuwerten \\ \hline
\end{tabularx}
\label{tab:ebpf_maps}
\end{table}


\subsection{Funktionsweise}

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\textwidth]{pictures/ebpf_component_2.drawio.png}
	\caption{Funktionsweise des eBPF Programmes (vereinfacht)}
	\label{fig:ebpf_component_diag}
\end{figure}

Wie in Abbildung \ref{fig:ebpf_component_diag} zu sehen, wird aus allen empfangenen Pakete zuerst der Ethernet-, IP- und TCP Header extrahiert und 
überprüft. Sollte dabei festgestellt werden, dass ein Paket kein valides IPV4-SYN/ACK Paket darstellt, wird es per XDP\_PASS an den normalen 
Netzwerkstack des Kernels weitergeleitet. Auch in der anschließenden Prüfung, ob die, da es sich in dem Fall um eine Antwort handelt, Ziel IP Adresse
in der WHITELIST\_IPV4 vertreten ist oder die Prüfung des SYN Cookies führt bei Fehlschlag zu einem XDP\_PASS. Das bietet den Vorteil, 
dass der reguläre Netzwerkverkehr trotz Nutzung des SYN Scanners unbeeinträchtigt ist. Um den SYN Cookie zu vergleichen wird die Hash-Berechnung 
mithilfe des Sip-Hashing Algorithmus und des per SIPHASH\_KEY übergegeben Schlüssels durchgeführt. Die vier in \ref{equqasion} genannten 
Werte werden wie in \ref{SYN-cookie grundlagen} beschrieben verrechnet und das Ergebnis verglichen (siehe \ref{equasion}) um die Anforderung \hyperref[req:F-05]{/F-05/} 
zu erfüllen.

% TODO möglicherweise mit Quellen belegen müssen und schauen ob teilweise begriffe deutsch sein sollten (wie Memory Allocator)
In dem eBPF Programm können aus mehreren Gründen keine Funktionen der Standardbibliothek von Rust genutzt werden. Zum Beispiel würden viele Funktionen 
schlichtweg nicht funktionieren, da sie per System Call auf Betriebssystemdiensten beruhen die hier nicht verfügbar sind, weil direkt im Kernel 
gearbeitet wird. Dynamische Speicherstrukturen wie Vec<T>, String, oder HashMap können nicht genutzt werden, da kein 
Zugriff auf den allgemeinen Memory Allocator besteht. Im Allgemeinen ist der eBPF Verifier sehr restriktiv, weshalb im eBPF Programm nur
wenige Bibliotheken nutzbar sind. In allen bereits beschriebenen Schritten des eBPFs wurde deshalb mit dem network\_types Crate gearbeitet.
Dieser nutzt keine Technologien der Standardbibliothek und erlaubt es, die rohen Speicherbereiche abstrahiert darzustellen und Zeiger auf
die Strukturen der Header mit leichter verständlichen Enums darzustellen. So können die gewünschten Paketstrukturen gelesen und 
verändert werden, ohne, dass neuer Speicher allokiert werden muss. 

Die Vermeidung neuer Speicherallokation wird unter anderem durch die Nutzung der ptr\_at Funktion umgesetzt. 
Die ptr\_at Funktion dient der Navigation durch den per ctx übergebenen Speicherbereich, indem ein Offset übergeben und Pointer vom Punkt
des Offsets aus bis zum Ende des Speicherbereichs zurückgegeben werden.

% müssen Teile des Codes zum Verständnis erkärt werden wir zB mut?
\begin{lstlisting}[caption={ptr\_at Funktion zum Navigieren durch Speicherbereiche},label=lst:ptr_at]
#[inline(always)]
unsafe fn ptr_at<T>(ctx: &XdpContext, offset: usize) -> Result<*const T, ()> {
    let start = ctx.data();
    let end = ctx.data_end();
    let len = mem::size_of::<T>();
    if start + offset + len > end {
        /* Error handling */
    }
    Ok((start + offset) as *const T)
}
\end{lstlisting}

So wird beispielsweise im folgenden Beispiel der Speicherbereich des IP Headers extrahiert, indem der Offset eines Ethernet Headers (16 Byte)
übergeben wird. 

\begin{lstlisting}[caption={Extraktion des Speicherbereichs des IP Headers},label=lst:ptr_at]
    // IPv4 Header
    let ip: *mut Ipv4Hdr = match unsafe { ptr_at_mut(ctx, EthHdr::LEN) } {
        Ok(p) => p,
        Err(_) => {
            /* Error handling */
        }
    };
\end{lstlisting}

Dabei ist zu beachten, dass diese Aufrufe von einem unsafe Block umschlossen sind. Da dieser Speicher vom Linux-Kernel und nicht von der Rust-Runtime 
verwaltet wird, kann Rust nicht sicherstellen, dass die Rust-typischen Sicherheitsgarantien gewährleistet sind. Diese Entscheidung wurde bewusst 
getroffen, da diese Arbeit performance-orientierte Implementierungen behandelt auch wenn dadurch Sicherheitsgarantien von Rust umgangen werden. 
Durch die besonderen Umstände im Kontext eines eBPF Programmes mit strengem Verifier sind die Sicherheitskonzepte kaum umsetzbar, wenn zero-copy
angestrebt wird. Dies hängt damit zusammen, dass Rust normalerweise mit einem panic! regiert, sollte beispeilsweise auf einen falschen Index eines
Slices (z.B. \&[u8]) zugegriffen werden. Dies ist im Kernel Kontext nicht erlaubt. Stattdessen bleibt die Möglichkeit eine Kopie des Speicherbereichs
anzufertigen, so wie es beispielsweise der etherparse Crate tut, um die Struktur dann in einem Sicheren Kontext zu verwalten. Dies mindert aber die 
Performanz deutlich und ist somit für performanz-orientiere Anwendungen wie die hier implementierte, besonders im Kernel Kontext, in welchem nur 
kleine Puffer existieren, nicht die präferierte Lösung.

Wenn sich ein Paket als valide Anwort herausstellt, werden die Zieldaten über den RingBuf an den Userspace weitergeleitet. Die Daten werden in der
in xdp\_common definierten Struktur namens PacketLog übertragen, welche die gescannte Adresse und den gescannten Port beinhaltet. Das xdp\_common
Verzeichnis dient lediglich der Definition dieser Struktur und dazugehörigen Getter Funktionen.

Das anschließende Erstellen und Versenden des RST Paketes dient einerseits dazu die Verbindung beim Zielsystem korrekt zu schließen und somit einen 
normalen TCP-Aushandlungsprozess zu simulieren, andererseits hindert es das Zielsystem am Senden weiterer SYN ACK Antworten sowie dem Aufrechterhalten
eines Verbindungsstatuses. Um die Performanz zu erhöhen wird auch hier ein zero-copy Ansatz gewählt, indem das ursprüngliche Paket durch das Tauschen
entsprechender Werte und das Neuberechnen einiger Werte umgewandelt wird. Die veränderten Felder sind im Folgenden Diagramm beschrieben:

% urg_ptr und weitere Elemente vergessen
\begin{figure}[h]
    \centering
    % Die resizebox sorgt dafür, dass die Grafik exakt die Seitenbreite nutzt
    \resizebox{\textwidth}{!}{%
    \begin{tikzpicture}[
        font=\sffamily\small,
        % Grundstil für die Speicherblöcke
        packetbyte/.style={
            draw, 
            minimum height=1cm, 
            rectangle, 
            align=center, 
            inner sep=4pt,
            outer sep=0pt
        },
        % Farben für die Header
        eth color/.style={fill=blue!10},
        ip color/.style={fill=green!10},
        tcp color/.style={fill=orange!10},
        data color/.style={fill=gray!20},
        % Stil für vertikale Operations-Pfeile (jetzt schwarz)
        op_arrow/.style={
            ->, 
            thick, 
            color=black, % Farbe geändert auf Schwarz
            >=Stealth,
            shorten >=0pt 
        },
        % Stil für Tausch-Pfeile (gebogen, jetzt schwarz)
        swap_arrow/.style={
            <->, 
            thick, 
            color=black, % Farbe geändert auf Schwarz
            >=Stealth,
            shorten >=0pt,
            shorten <=0pt
        },
        % Beschriftungen über Pfeilen
        arrow_label/.style={
            anchor=south, 
            font=\sffamily\footnotesize\bfseries, 
            inner sep=2pt,
            align=center,
            color=black % Textfarbe Schwarz
        }
    ]

        %% --- REIHE 1: ETHERNET HEADER ---
        \node[packetbyte, eth color, minimum width=4cm] (eth_dst) {Dest MAC};
        \node[packetbyte, eth color, minimum width=4cm, right=0cm of eth_dst] (eth_src) {Source MAC};
        \node[packetbyte, eth color, minimum width=3cm, right=0cm of eth_src] (eth_type) {Type};
        \node[right=0.5cm of eth_type, font=\bfseries\large, anchor=west] {Ethernet Header};

        %% --- REIHE 2: IP HEADER ---
        \node[packetbyte, ip color, minimum width=2cm, below=3.5cm of eth_dst.west, anchor=west] (ip_ver) {Ver/HL};
        \node[packetbyte, ip color, minimum width=2cm, right=0cm of ip_ver] (ip_tos) {TOS};
        \node[packetbyte, ip color, minimum width=3cm, right=0cm of ip_tos] (ip_len) {Total Len};
        \node[packetbyte, ip color, minimum width=4cm, right=0cm of ip_len] (ip_rest) {\dots ID/Frag \dots};
        \node[packetbyte, ip color, minimum width=2.5cm, right=0cm of ip_rest] (ip_chk) {Checksum};
        \node[packetbyte, ip color, minimum width=3cm, right=0cm of ip_chk] (ip_src) {Src IP};
        \node[packetbyte, ip color, minimum width=3cm, right=0cm of ip_src] (ip_dst) {Dest IP};
        \node[right=0.5cm of ip_dst, font=\bfseries\large, anchor=west] {IP Header};

        %% --- REIHE 3: TCP HEADER ---
        \node[packetbyte, tcp color, minimum width=3cm, below=3.5cm of ip_ver.west, anchor=west] (tcp_src) {Src Port};
        \node[packetbyte, tcp color, minimum width=3cm, right=0cm of tcp_src] (tcp_dst) {Dest Port};
        \node[packetbyte, tcp color, minimum width=3.5cm, right=0cm of tcp_dst] (tcp_seq) {Seq Num};
        \node[packetbyte, tcp color, minimum width=3.5cm, right=0cm of tcp_seq] (tcp_ack) {Ack Num};
        \node[packetbyte, tcp color, minimum width=2.5cm, right=0cm of tcp_ack] (tcp_flags) {Flags};
        \node[packetbyte, tcp color, minimum width=2.5cm, right=0cm of tcp_flags] (tcp_chk) {Checksum};
        \node[right=0.5cm of tcp_chk, font=\bfseries\large, anchor=west] {TCP Header};

        %% --- REIHE 4: PAYLOAD / OPTIONS ---
        \node[packetbyte, data color, minimum width=18cm, below=3.5cm of tcp_src.west, anchor=west, dashed] (payload) {TCP Options \& Payload};
        \node[right=0.5cm of payload, font=\bfseries\large, text=gray, anchor=west] {Verworfen};

        %% --- OPERATIONEN ---

        % 1. Ethernet Swap
        \draw[swap_arrow] (eth_src.north) to[bend right=45] node[midway, above, font=\bfseries] {Tausche} (eth_dst.north);

        % 2. IP Address Swap
        \draw[swap_arrow] (ip_src.north) to[bend left=60] node[midway, above, font=\bfseries] {Tausche} (ip_dst.north);

        % 3. Set IP Total Length
        \draw[op_arrow] ($(ip_len.north)+(0,0.8)$) node[arrow_label] {Setze 40 Bytes\\(IP + TCP Header)} -- (ip_len.north);

        % 4. Calc IP Checksum
        \draw[op_arrow] ($(ip_chk.north)+(0,0.8)$) node[arrow_label] {Berechne neu} -- (ip_chk.north);

        % 5. Port Swap
        \draw[swap_arrow] (tcp_src.north) to[bend left=60] node[midway, above, font=\bfseries] {Tausche} (tcp_dst.north);

        % 6. Ack -> Seq (Farbe auf Schwarz geändert)
        \draw[->, thick, color=black, >=Stealth] (tcp_ack.north) to[bend right=65] node[midway, above, font=\bfseries\footnotesize] {Kopiere in Seq Num} (tcp_seq.north);

        % 7. Set RST Flag
        \draw[op_arrow] ($(tcp_flags.north)+(0,0.8)$) node[arrow_label] {Setze RST} -- (tcp_flags.north);

        % 8. Calc TCP Checksum
        \draw[op_arrow] ($(tcp_chk.north)+(0,0.8)$) node[arrow_label] {Berechne neu} -- (tcp_chk.north);

        % 9. Visual Cut (Zentriert im nun größeren Abstand)
        \begin{scope}[shift={($(payload.north) + (0, 1.25)$)}] 
            % Pfeil ist nun normal (nicht gestrichelt) und schwarz
            \draw[->, thick, color=black, >=Stealth] (0, 1.0) -- (0, -1.0);
            
            % Das Kreuz (bleibt rot als Highlight)
            \node[scale=0.8, anchor=center] at (0,0) {
                \tikz{
                    \draw[ultra thick] (-0.3,0.3) -- (0.3,-0.3);
                    \draw[ultra thick] (-0.3,-0.3) -- (0.3,0.3);
                }
            };
            % Text ist nun schwarz
            \node[color=black, right, font=\bfseries] at (0.4,0) {Abschneiden};
        \end{scope}

    \end{tikzpicture}
    }
    \caption{In-Memory Modifikation des SYN ACK Paketes zum RST Paket}
\end{figure}

Das fertige Paket wird anschließend per XDP\_TX direkt in den Puffer der Netzwerkkarte geschrieben und durch die Modifikationen
als valides RST Paket an den Sender der ursprünglichen SYN ACK Antwort zurückgeschickt. Dies dient der Erfüllung der Anforderung 
\hyperref[req:F-06]{/F-06/}.

%\section{Lazy Expiration}

\section{Qualitätssicherung}

% ALLGEMEINES TODO AUF RELEVANTE SUBSUBSECTIONS WIE RATE_LIMITER ODER SENDER KONKRETER EINGEHEN
% PERFORMANCE MAßNAHMEN, SPEZIFISCHE FUNKTIONSWEISE -> ÄHNLICH WIE BEI std_in_parser / eBPF



% !TEX root = ../Thesis.tex
%%
%%  Hochschule für Technik und Wirtschaft Berlin --  Abschlussarbeit
%%
%% Kapitel 5 - Tests
%%
%%

\chapter{Konzeption und Implementierung} \label{Implementierung}
In diesem Kapitel wird zuerst das Konzept zur Erfüllung der Anforderungen vorgestellt.
Anschließend wird die konkrete Umsetzung der Komponenten detailliert 
dargelegt und erklärt. Die folgende Beschreibung der Architektur und Implementierung dient gemäß \cref{Methodik} zugleich als Nachweis 
für die Erfüllung der Anforderungen, die durch statische Inspektion verifiziert werden.

Der gesamte Quellcode ist auf GitHub bereitgestellt \cite{F4c3hugg3r_2026}.

\section{Konzeptioneller Lösungsansatz}
Zur Verdeutlichung des Softwareentwurfs werden in diesem Abschnitt zunächst die logischen Komponenten 
der Anwendung und deren Zusammenspiel vorgestellt. Im Anschluss daran werden die spezifischen Maßnahmen erläutert, 
die zur Steigerung der \eng{Performance} und Effizienz ergriffen wurden.

\subsection{Logische Komponenten des Scanners} \label{impl:logische_komponenten}
\Cref{fig:component_diag} visualisiert die logischen Komponenten des Scanners sowie deren Interaktionen.
Um die in \cref{req:NF-02} geforderte Asynchronität sowie die Entkopplung von Sende- und Empfangsprozessen zu realisieren, 
folgt die Architektur einem \eng{Pipeline}-basierten Ansatz. Dabei werden die einzelnen Module lose gekoppelt und 
kommunizieren über sogenannte \eng{Channels} miteinander. Diese dienen nicht nur dem Datenaustausch, sondern fungieren 
gleichzeitig als Puffer, um temporäre Lastspitzen auszugleichen. Durch diese Modularisierung wird sichergestellt, dass 
\eng{I/O}-intensive Aufgaben wie das Lesen der Eingabedaten rechenintensive Prozesse wie die Paketkonstruktion 
nicht blockieren. In der Darstellung wird zudem zwischen Kontrollflüssen, die einmalig Informationen wie Startbefehle und Parameter 
übertragen, und kontinuierlichen Datenflüssen differenziert. 

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\textwidth]{pictures/Kopie von Komponentendiagramm-SYN-Rust_nr.drawio.pdf}
	\caption{Diagramm logischer Komponenten des Scanners (vereinfacht)}
	\label{fig:component_diag}
\end{figure}

Das Startprogramm erstellt Paketrohlinge und dient der Eingabe sowie Übergabe der Konfigurationsdaten.
Außerdem startet es das Scanner-Programm. Die Jobverwaltung hat hauptsächlich
die Aufgabe, die anderen Komponenten korrekt zu vernetzen und zu starten. Die Paketemissionierung übernimmt die Paketbearbeitung, 
die Durchsatzlimitierung und das Versenden der Pakete. Für die Aufgabe des Empfangens und Auswerten der Antwortpakete sind zum einen ein 
\texttt{eBPF}-Programm zuständig, welches im Komponentendiagramm an der \eng{Netzwerkinterface}-Komponente
angesiedelt ist und zum anderen die Ergebnisverarbeitung. Letzteres beinhaltet die Logik für den Empfang der vom \texttt{XDP}-Programm übermittelten Daten im \eng{User-Space} 
sowie für die anschließende Duplikatsentfernung. In dem Diagramm ist zu erkennen, dass 
zwischen der Paketemissionierungs-Komponente und der Ergebnisverarbeitungs-Komponente kein Datenfluss besteht, sondern lediglich das 
Signal zum Beenden des Scans ausgetauscht wird. Daran ist das zustandslose Design zu erkennen, 
welches die Anforderung \cref{req:F-04} erfüllt. 

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\textwidth]{pictures/TX_RX_Kernel_nr.drawio.pdf}
	\caption{Weg der Pakete durch den Linux-Kernel im SYN-Rust Scanner (vereinfacht)}
	\label{fig:kernel_diag}
\end{figure}

In \cref{fig:component_diag} wird der Weg der Pakete durch den Netzwerkkartentreiber und die Trennung der Zuständigkeiten
von \eng{User-Space} und Linux-Kernel nicht explizit behandelt. Um nun aber die Funktionsweise des \texttt{eBPF}-Programmes zu verbildlichen,
wird in \cref{fig:kernel_diag} der Datenfluss zwischen Scanner-Programm und Netzwerkkarte verdeutlicht.
Das Diagramm zeigt mögliche Pfade, die ein Paket durchläuft, wenn es entweder gesendet oder empfangen wird. 
% Platz sparen und ist schon in Grundlagen besprochen worden
%Dabei werden auch die unterschiedlichen
%XDP-Modi (siehe \cref{Grundlagen.XDP}) beachtet. Im Sendeprozess (von der Anwendung zur Netzwerk-Hardware) wird mithilfe von \texttt{AF\_XDP} der Netzwerk-Stack 
%des Kernels je nach \eng{Socket}-Konfiguration (\eng{Copy} oder \eng{Zero-Copy}) vollständig oder zum Großteil übersprungen. Die \texttt{AF\_PACKET}-Variante
%hingegen durchläuft immer einige wenige Schritte des regulären Netzwerkstacks. 
Im Empfangsprozess ist zu sehen, dass das \texttt{eBPF}-Programm 
je nach Modus (\eng{SKB Mode} oder \eng{Driver Mode}) im Treiber der Netzwerkkarte oder direkt zu Beginn des Kernel-Netzwerkstacks ausgeführt wird.
In beiden Fällen werden dort die eingehenden Pakete zuerst untersucht und je nach Ergebnis der Untersuchung 
direkt verworfen, an den Netzwerkstack weitergeleitet oder verändert und an den Treiber oder per \texttt{XDP\_TX} direkt an die Netzwerkkarte zum Versenden
zurückgegeben. So werden alle Schritte (oder im Falle des \eng{SKB Mode} fast alle) des regulären Netzwerkstacks eingespart.
Die Ergebnisse der Untersuchung im \texttt{eBPF}-Programm werden bei gültigen Paketen in eine \texttt{eBPF Map}, 
in diesem Fall einen \texttt{RingBuf} (siehe \cref{ebpf:xdp_program}), geloggt.
Dies hat den Vorteil, dass nur die relevanten Inhalte des Pakets (IP-Adresse, Port) statt des gesamten Pakets übermittelt werden müssen.
Außerdem hat das \eng{User-Space}-Programm direkten Zugriff auf den \texttt{RingBuf} und kann die Daten somit ohne Umwege abgreifen.

Auf diese Art und Weise kann der SYN-Scanner die Verarbeitungsschritte sowohl beim Senden als auch beim Empfangen von Paketen auf 
ein Minimum reduzieren, sodass CPU-Zyklen fast ausschließlich für die Anwendungslogik und nicht für das Betriebssystem aufgewendet werden. 
Dies validiert die konsequente Nutzung moderner Kernel-Mechanismen (\cref{req:NF-03}) unter Berücksichtigung der technologischen Einschränkung auf das Linux-Ökosystem (\cref{req:NF-06}) und bringt große Performanzpotenziale mit sich.

\clearpage
\subsection{Performancesteigernde Maßnahmen} \label{impl:performance_steigernde_maßnahmen}
Neben der in \cref{ebpf:xdp_program} gezeigten Kernelumgehung werden zur Maximierung des Durchsatzes (\cref{req:NF-01}) und Minimierung der Ressourcennutzung (\cref{req:NF-05}) 
zwei weitere Maßnahmen verfolgt:

\begin{enumerate}
    \item \textbf{\eng{Batching}:} Sowohl im Datenaustausch zwischen den Komponenten mithilfe von \eng{Channels} als auch beim 
    Versenden von Paketen werden die Daten immer in \eng{Batches} übertragen. 
    Im Kontext der \eng{Channels} bedeutet dies, dass statt einzelner Nachrichten Vektoren mit einer Vielzahl von Objekten übermittelt werden. 
    Dies senkt den Synchronisationsaufwand pro Element erheblich, da die Anzahl der Interaktionen mit dem \eng{Channel} minimiert wird.
    Für das Senden von Paketen reduziert das \eng{Batching} die Anzahl der \eng{System Calls}. 
    Durch die gebündelte Verarbeitung mehrerer Pakete in einem Durchlauf wird der \eng{Overhead} durch \eng{Context Switches} zwischen \eng{User-Space} und \eng{Kernel-Space} verringert.     
    \item \textbf{Vermeidung von Kopieroperationen und \eng{Context Switches}:} 
    Zur Reduktion dynamischer Speicherzuweisungen (Allokationen) werden Vektoren, falls möglich, mit einer festen Kapazität initialisiert, 
    um Reallokationen zur Laufzeit zu vermeiden. Bereits verwendete Vektoren werden nicht verworfen, sondern lediglich geleert und wiederverwendet.
    Zudem wurde beim Design auf die Vermeidung von Kopieroperationen geachtet. Das \texttt{eBPF}-Programm (siehe \cref{eBPF}) arbeitet beispielsweise direkt auf Referenzen 
    des Speicherbereichs (\eng{Zero-Copy}), und auch die für das \eng{Parsing} der IP-Adressen vom Startprogramm zuständige Komponente nutzt Mechanismen, 
    um Kopieroperationen zu vermeiden (siehe \cref{jobverwaltung:parser}).
\end{enumerate}

\section{Implementierung und Funktionsweise der Komponenten}
Um die Funktionsweise des Programmes im Detail zu erklären, wird zuerst der Projektaufbau erklärt und anschließend 
die einzelnen Quelldateien vorgestellt und Besonderheiten bezüglich performanzsteigernder oder ressourcensparender Umsetzungen erläutert.

\subsection{Projektstruktur Basisimplementierung}
Die Verzeichnisse sind nach Aufgabenbereichen gegliedert, um klar zeigen
zu können, welches Verzeichnis für welche Aufgabe zuständig ist und somit die Übersichtlichkeit zu steigern. 
Das Rust-Projekt hat folgende Ordnerstruktur:

\begin{lstlisting}[caption=Ordnerstruktur des SYN-Scanners (gekürzt)]{Projektstruktur Basisimplementierung}
/scanner                                     
    /src
        /bin
            mock_programm.rs
        /scan utils                                    
            /capturing_packets
                bucket.rs
                receiver.rs
            /emitting_packets
                assembler.rs
                rate_limiter.rs
                sender.rs
            /job_controlling
                parser_std_in.rs
                scan_job.rs
            /shared
                helper.rs
                types_and_config.rs
        main.rs
    Cargo.toml
/xdp-common
    /src
        lib.rs
/xdp-ebpf
    /src
        main.rs
...

\end{lstlisting}

In jedem Ordner ist eine \texttt{mod.rs} Datei zu finden, welche hier zugunsten der Lesbarkeit entfernt wurden.
Diese Dateien dienen dazu, ein Verzeichnis als Rust-Modul zu definieren und die darin genutzten Dateien für den 
Compiler sichtbar zu machen. Die \texttt{Cargo.toml} ist für die Verwaltung der externen Bibliotheken zuständig.
 
Die Zuordnung der Verzeichnisse zu den logischen Komponenten ist in \cref{fig:component_diag} zu finden.
Die Verzeichnisse \texttt{xdp-ebpf} und \texttt{xdp-common}, welche dort nicht explizit genannt werden, da sie im Kernel-Kontext ausgeführt werden,
beschreiben das \texttt{eBPF}-Programm, welches Antwortpakete abfängt, auswertet und nur die relevanten Informationen an den
\eng{User-Space} weiterleitet. Das Verzeichnis \texttt{shared} dient lediglich der Steigerung der Übersichtlichkeit. Es enthält
Hilfsfunktionen sowie Typenbeschreibungen, die mehrfach im Projekt genutzt werden. Somit dient es rein der Code-Organisation.

\subsection{Übersicht genutzter \eng{Crates}}
Für die Umsetzung der Komponenten sind die in \cref{tab:crates_all} beschriebenen \eng{Crates} aufgrund ihrer Wichtigkeit hervorzuheben.

\begin{table}[htbp]
\begin{tabularx}{\textwidth}{|c|c|X|}\hline 
\textbf{\eng{Crate}} & \textbf{Version} & \textbf{Nutzung} \\ \hline
\texttt{tokio} & 1.47.1 & Nutzung für asynchrone Komponenten, Kommunikation über \eng{Channels}, \eng{Parsing} des \eng{Standard Input} und Starten mehrerer asynchron laufender \eng{Tasks} \\ \hline
\texttt{nix} & 0.30.1 & Erstellen der \texttt{AF\_PACKET}-Schnittstelle und Versenden darüber \\ \hline
\texttt{xdp-socket} & 0.1.4 & Erstellen der \texttt{AF\_XDP}-Schnittstelle und Versenden darüber \\ \hline
\texttt{aya} & 0.13.1 & Erstellung und Nutzung von \texttt{eBPF}-Programmen mittels bereitgestellter Werkzeuge und Strukturen \\ \hline
\texttt{dashmap} & 6.1.0 & Nutzung von für asynchrone Umgebungen optimierten \eng{HashMaps} mit selbstständigem \eng{Locking} \\ \hline
\texttt{pnet} & 0.35.0 & Nutzung als abstrahiertes Netzwerkwerkzeug zur Erstellung der \eng{Packet Templates} \\ \hline
\texttt{network\_types} & 0.1.0 & \eng{Parsing} der \eng{Header}-Strukturen aus rohem Speicherbereich, ohne diese zu kopieren \\ \hline
\end{tabularx}
\caption{Genutzte \eng{Crates}}
\label{tab:crates_all}
\end{table}

\subsection{Paketemissionierung (\texttt{emitting\_packets})}
Die Paketemissionierung umfasst den Prozess der Durchsatzlimitierung, der Paketverarbeitung und des Paketversandes inklusive
den dafür benötigten Vorbereitungsschritten.

\subsubsection{\eng{Rate Limiter} (\texttt{rate\_limiter.rs})}
Wie in \cref{fig:emitting_sequence_diag} zu sehen, führt der \eng{Rate Limiter} (\texttt{rate\_limiter.rs})
die Funktion der Durchsatzlimitierung (\cref{req:F-08}) aus. Zuerst nimmt er die zu scannenden IP-Adressen vom \eng{Parser} (\texttt{parser\_std\_in})
entgegen, bestimmt die Puffergröße anhand der in dieser Sekunde bereits gesendeten Datenmenge, füllt einen Puffer und erstellt 
für jeden Puffer einen \texttt{tokio} \eng{Task} mit einem \eng{Assembler} (\texttt{assembler.rs}).
Sobald alle IP-Adressen initial verarbeitet sind, erfolgt der Durchlauf für die übrigen Zielports. Dabei wird ressourcenschonend auf den internen Puffer 
zurückgegriffen, wodurch erneutes Parsen entfällt.

\texttt{tokio} \eng{Tasks}, auch als \eng{Green-Threads} bekannt, sind leichtgewichtige, von der Laufzeitumgebung verwaltete Ausführungseinheiten. 
Im Gegensatz zu Betriebssystem-\eng{Threads} blockieren sie bei Warteoperationen nicht, sondern geben Ressourcen dynamisch frei, 
was eine effiziente, asynchrone Nebenläufigkeit ermöglicht \cite{tokio::task_Rust}. 

Diese Nebenläufigkeit wird hier genutzt, um entsprechend der aktuellen 
Senderate \eng{Assembler} zu erzeugen, die nicht den gesamten \eng{Thread} des Betriebssystems blockieren, wenn die Pakete eines spezifischen \eng{Assemblers} nicht als Erstes 
vom \eng{Sender} entgegengenommen werden. Stattdessen wartet jeder \eng{Assembler}, ohne andere Teile der Software zu beeinträchtigen. So wird sichergestellt,
dass immer genügend Pakete für den \eng{Sender} bereitstehen. Die Puffergröße eines \eng{Assemblers} wird bei Beginn des Programmes abhängig von der Durchsatzlimitierung
und der \eng{Batch}-Größe rechnerisch wie folgt ermittelt: 

\begin{equation} \label{equ:rl_1}
    S_{opt}(R, B) =
    \begin{cases}
        65536 & \text{falls } R = 0 \\
        \left\lceil \frac{\operatorname{clamp}(N_{target}, N_{min}, N_{max})}{B} \right\rceil & \text{sonst}
    \end{cases}
\end{equation}

\noindent Wobei $N_{target}$ die ideale Anzahl an Paketen pro Verarbeitungszyklus beschreibt:

\begin{equation} \label{equ:rl_2}
    N_{target} = \frac{R \cdot 10^6}{8 \cdot 60 \cdot 10}
\end{equation}

\noindent Die Variablen sind hierbei wie folgt definiert:

\begin{itemize}
    \item $S_{opt}$: Die berechnete optimale Puffergröße (in Anzahl der Batches).
    \item $R$: Die gewünschte Scan-Rate in Mbit/s.
    \item $B$: Die konfigurierte Batch-Größe (Anzahl Pakete pro Batch).
    \item $N_{min}, N_{max}$: Heuristische Grenzen für die Puffergröße ($2048$ bzw. $262144$ Pakete).
\end{itemize}

\noindent Die numerischen Konstanten in \cref{equ:rl_2} haben folgenden Zweck:

\begin{itemize}
    \item Der Faktor $\frac{10^6}{8}$ konvertiert die Rate $R$ von Mbit/s in Byte/s.
    \item Der Wert $60$ repräsentiert die Größe eines TCP-SYN-Pakets in Byte.
    \item Der Divisor $10$ definiert die Ziel-Frequenz der \eng{Wakeups} ($10\,\text{Hz}$). 
    Dies bedeutet, dass der Puffer so dimensioniert wird, dass er Daten für ein Zeitintervall von $100\,\text{ms}$ vorhält.
\end{itemize}

Die optimale Puffergröße für die Paketerstellung wird dynamisch auf Basis der gewünschten Senderate und der konfigurierten 
\eng{Batch}-Größe berechnet. Ziel ist es, genügend Daten für ein Verarbeitungsintervall von 100 ms vorzuhalten. 
Dies minimiert die CPU-Last, indem Kontextwechsel gespart werden, da die \texttt{tokio}-Runtime nur wenige \eng{Assembler-Tasks}
aufwecken muss.

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\textwidth]{pictures/Emitting_Sequenz_nr.drawio.pdf}
	\caption{Ablauf und Funktionsweise der \texttt{emitting\_packets}-Komponente (vereinfacht)}
	\label{fig:emitting_sequence_diag}
\end{figure}

\subsubsection{\eng{Assembler} (\texttt{assembler.rs})}
Die Rolle des \eng{Assemblers} ist recht simpel: Jeder \eng{Assembler} iteriert über die ihm verfügbaren IP-Adressen, füllt \eng{Templates} mit 
der Ziel-IP-Adresse, dem Ziel-Port sowie der \eng{Sequence Number} und berechnet die Checksummen des \eng{IP-Header} und \eng{TCP-Header} neu. 
Dies dient zur Erfüllung der Anforderung \cref{req:F-01}. Die \eng{Sequence Number} wird wie folgt berechnet:
\begin{equation}
    \text{ISN} = \text{SipHash}_{K}(\texttt{src\_ip}, \texttt{dst\_ip}, \texttt{src\_port}, \texttt{dst\_port})
\end{equation} \label{equ:syn_cookie_umsetzung}

\noindent wobei:
\begin{itemize}
    \itemsep 0pt
    \item \textbf{\text{ISN}:} die berechnete 32-Bit initiale \eng{Sequence Number} (\texttt{SYN}-Cookie).
    \item \textbf{\text{K}:} ein geheimer, zufälliger 128-Bit Schlüssel, der beim Start des Scanners generiert wird.
    \item \textbf{\texttt{src\_ip}, \texttt{dst\_ip}:} die Quell- und Ziel-IP-Adressen der Verbindung.
    \item \textbf{\texttt{src\_port}, \texttt{dst\_port}:} die zugehörigen TCP-Quell- und Ziel-Ports.
\end{itemize}

Die Pseudozufallsfunktion \eng{SipHash} eignet sich hervorragend, da sie speziell für hohe \eng{Performance} bei kurzen Eingabedaten entwickelt wurde, aber 
einer Hash-Funktion entsprechend bei gleichem Input immer den gleichen Wert zurückgibt \cite{SipHash_a_short_input_PRF_The_Linux_Kernel_documentation}.
Damit dies konsistent funktioniert, muss allerdings ein geheimer Schlüssel genutzt werden, welcher der Paketemissionierungs- sowie der \texttt{eBPF}-Komponente bekannt ist.
In den \eng{Templates} sind die restlichen Werte bereits vorhanden. Die Änderungen werden direkt auf Byte-Ebene umgesetzt, da die Feldzuweisungen der 
\eng{Header}-Felder immer gleich sind \cite{Eddy_2022} \cite{Postel_1981}.
Somit können vollständige Pakete in sehr wenigen Schritten und ohne aufwendiges \eng{Parsing} oder gar komplette Neuerstellung genutzt werden. 
Diese Pakete werden anschließend je nach Konfiguration in \eng{Batches} an den \eng{Sender} weitergeleitet.

\subsubsection{\eng{Sender} (\texttt{sender.rs})}
Im Gegensatz zu den übrigen Subkomponenten operiert der \eng{Sender} in einem dedizierten Betriebssystem-\eng{Thread}. 
Dies gewährleistet die exklusive Nutzung der verfügbaren Rechenkapazität und minimiert Prozesskonflikte. 
Zur weiteren Optimierung wird mittels der \texttt{core\_affinity}-\eng{Crate} (siehe \cref{tab:crates_all}) eine feste Bindung 
an einen CPU-Kern erzwungen. Dies verbessert die \eng{Cache}-Lokalität und verhindert teure Wechsel zwischen Kernen, 
was für konsistent hohe Senderaten von Vorteil ist \cite[S.~181]{Balasubramanian2017System}. 
Der \eng{Sender} verarbeitet in einer Endlosschleife eingehende Paket-\eng{Batches} 
über die beim Start initialisierte Netzwerkschnittstelle (vgl. \cref{req:F-02}), bis die Kommunikationskanäle geschlossen werden. 

Um eine fundierte Vergleichsbasis zu schaffen und den tatsächlichen Mehrwert komplexer Verfahren zu evaluieren, 
unterstützt die Implementierung sowohl \texttt{AF\_PACKET} als auch \texttt{AF\_XDP} als Sende-Backend. Der Sendeprozess eines
\eng{Batches} ist in \cref{fig:send_af_xdp} beschrieben.

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\textwidth]{pictures/XDP Batch Processing-2026-02-14-183034.png}
	\caption{Ablauf des Sendens von Batches via AF\_XDP in SYN-Rust (vereinfacht)}
	\label{fig:send_af_xdp}
\end{figure}

\subsection{Ergebnisverarbeitung (\texttt{capturing\_packets})}
In der Ergebnisverarbeitung werden die durch den \texttt{eBPF} vorgeprüften Daten der gültigen Antworten entgegengenommen und einer
Duplikatsprüfung unterzogen. Anschließend werden die endgültig korrekten Ergebnisse ausgegeben.   

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\textwidth]{pictures/capturing_neu_nr.drawio.pdf}
	\caption{Exemplarisches Diagramm zur Funktionsweise der \texttt{capturing\_packets}-Komponente (vereinfacht)}
	\label{fig:capturing_sequence_diag}
\end{figure}

\subsubsection{\eng{Receiver} (\texttt{receiver.rs})}
In der initialen Entwicklungsphase (siehe \cref{fig:pcap}) operierte der \eng{Receiver}, ebenso wie der \eng{Sender}, in einem dedizierten Betriebssystem-\eng{Thread}. 
Um Anforderung \cref{req:F-03} zu erfüllen, kam dabei die Bibliothek \texttt{pcap} zum Einsatz, welche eine komfortable Abstraktion 
für den Netzwerkzugriff bietet und die Filterung via \textit{Berkeley Packet Filter} ermöglicht. 
Ein- und ausgehende Pakete wurden empfangen, mittels \texttt{etherparse} analysiert und anschließend auf Duplikate geprüft.

Trotz der entwicklerfreundlichen Handhabung wurde die Architektur zugunsten des deutlich leistungsfähigeren \texttt{eBPF}-Ansatzes 
umgestellt, um den \eng{High-Performance}-Ansprüchen dieses Projekts zu genügen. \texttt{pcap} basiert intern auf \eng{Raw-Sockets} 
(\texttt{PF\_PACKET}\footnote{Funktional äquivalent zu \texttt{AF\_PACKET} \cite{socket2_linux_manpage}}) \cite{the-tcpdump-group/libpcap_2026}, 
weshalb Pakete deutlich mehr Schritte als bei Nutzung eines \texttt{eBPF}-Programmes durchlaufen müssen (vgl. \cref{fig:kernel_diag}).

Im aktuellen Ansatz läuft der \eng{Receiver} stattdessen in einem \texttt{tokio} \eng{Task}, um Asynchronität zu gewährleisten. Außerdem dient 
er nun ausschließlich dem Empfang der durch das \texttt{eBPF}-Programm über den \texttt{RingBuf} geloggten Daten,
der Verwaltung der Duplikaterkennung und der Ausgabe gültiger Daten. Im ersten Schritt werden Daten aus dem \texttt{RingBuf} abgerufen. 
Da der Zugriff auf den \texttt{RingBuf} über einen Unix-Dateideskriptor erfolgt, dessen Leseoperationen standardmäßig den \eng{Thread} blockieren, 
muss dieser in das asynchrone Modell der Anwendung integriert werden.  Dafür bietet \texttt{tokio} eine Lösung, welche es ermöglicht, 
durchgehend auf neue Pakete zu warten, ohne den ausführenden \eng{Thread} zu blockieren. Anschließend wird die Ziel-IP-Port-Kombination der
Duplikatprüfung, welche im nächsten Absatz genauer beschrieben wird, unterzogen. Bei gültigen Ergebnissen (kein Duplikat) werden 
diese in einem Puffer gesammelt, welcher entweder bei Erreichen der maximalen Größe geleert wird. 
Die Daten werden über einen \eng{Channel} an einen separaten Schreiber-\eng{Task} übergeben, welcher die 
Ergebnisse effizient blockweise in den \eng{Standard Output} schreibt. Dies minimiert \eng{System Calls} für I/O-Operationen 
und erfüllt Anforderung \cref{req:F-07}.

Die Weiterleitung der Ergebnisse in eine Datei erfolgt anschließend durch das aufrufende Programm (siehe \texttt{mock\_program.rs}).

\subsubsection{\eng{Bucket} (\texttt{bucket.rs})}
Zur effizienten Duplikaterkennung wird ein \textit{Timed Bucket System} genutzt, in welchem mehrere 
\eng{Buckets}, welche intern eine \eng{DashMap} nutzen (siehe \cref{tab:crates_all}), als Zwischenspeicher für 
die bisherigen Antworten dienen. Es wird nur in den derzeit aktiven \eng{Bucket} geschrieben, doch aus allen wird gelesen. 
Nach einer festen Zeiteinheit\footnote{$1/x, x = \text{Anzahl der Buckets}$}
wird der nächste \eng{Bucket} aktiv und der am längsten inaktive geleert. 

Durch die Aufteilung in mehrere \eng{Buckets} sollen 
Lastspitzen durch das Leeren einer sehr aufgeblähten \eng{DashMap} verhindert werden. 
Außerdem werden dadurch längere \eng{Locking}-Zeiten bei asynchronen Schreib- und Lesezugriffen vermieden.
Die Suche nach Duplikaten gestaltet sich dabei schnell, da \eng{DashMaps} eine Suche der Zeitkomplexität $O(1)$ ermöglichen. 

\subsection{Programmstart und Jobverwaltung (\texttt{job\_controlling})}
Der Start des Programmes, die Konfiguration sowie das Starten und Verbinden der einzelnen Komponenten geht
von den in diesem Abschnitt beschriebenen Komponenten aus. Des Weiteren übernehmen diese auch das \eng{Parsing} und
die Weiterleitung der Ziel-IP-Adressen zur \texttt{emitting\_packets}-Komponente.  

\subsubsection{Startprogramm (\texttt{mock\_program.rs})}
Um die Anforderung \cref{req:F-09} zu erfüllen, nimmt der Scanner die IP-Adressen der Ziele über den \eng{Standard Input} entgegen.
Für die Evaluation in dieser Arbeit wurde, um die Vergleichbarkeit herzustellen, dieses Startprogramm erstellt. Es hat die Aufgabe,
den Scanner zu starten, \eng{Ethernet Templates} zu erstellen und Daten in den \eng{Standard Input} zu schreiben sowie Daten aus dem
\eng{Standard Output} des Scanners zu lesen. Im Startprogramm werden auch die Konfigurationsparameter eingetragen. 

Die \eng{Ethernet Templates}, welche das Fundament zur Erfüllung der Anforderung \cref{req:F-01} darstellen,
werden mithilfe des \texttt{pnet} \eng{Crates} erstellt, da dieser eine entwicklerfreundliche Schnittstelle dafür bereitstellt. 
Dort werden alle Parameter für eine reguläres \texttt{TCP-SYN}-Paket bis auf die Ziel-IP, den Ziel-Port und die \eng{Sequence Number} gesetzt. 
Es wird für jede Quell-IP ein \eng{Template} angelegt, um die Streuung der Paketquellen zur Verschleierung des Scans
und somit die Trefferrate zu erhöhen.

\subsubsection{Einstiegspunkt (\texttt{main.rs})}
Die \texttt{main.rs}-Datei dient als Einstiegspunkt und Startfunktion des SYN-Scanners. Dort wird mithilfe des \texttt{aya}-\eng{Crates} das \texttt{eBPF}-Programm 
geladen und die \texttt{eBPF-Maps} initialisiert. Des Weiteren werden die Konfigurationsparameter erfasst und letztendlich ein \eng{Scanjob} mit allen 
benötigten Informationen gestartet.

% testen ob das wirklich Vorteile bringt, denn es wird oft auf Zero-Copy geachtet und es gibt nicht super viele Threads (maybe eher durch besseres
% cache handling begründen) <- GANZEN ABSATZ BEI PLATZMANGEL ENTFERNEN
%Eine ressourcensparende Maßnahme ist außerdem die Nutzung eines alternativen \eng{Allocators}, 
%welcher in der \texttt{main.rs}-Datei definiert wird.
%Anstelle des \eng{System Allocators}, welcher ein breites Anwendungsfeld bedient, bietet der \texttt{jemallocator} einen Fokus auf Nebenläufigkeit
%und Skalierbarkeit auf Multiprozessorsystemen \cite{jemalloc}. Das wird dadurch erreicht, dass viermal mehr der sogenannten Arenen als 
%verfügbare Prozessoren erstellt und die \eng{Threads} darunter aufgeteilt werden. \eng{Threads} blockieren sich gegenseitig nur, wenn sie in der gleichen
%Arena sind, was durch die Vielzahl deutlich seltener vorkommt. Außerdem ist die Allokierung von Speicher durch die Nutzung fester \eng{Size Classes}
%für sehr viele kleine Allokationen, wie sie in dem Scanner zum Beispiel bei der Vielzahl an \eng{Batches} von IP-Adressen oder Pakete
%geschieht, effizienter, als die Vorgehensweise des \eng{System Allocators}, welcher die genaue Speichergröße sucht.

\subsubsection{\eng{Standard Input Parser} (\texttt{parser\_std\_in})} \label{jobverwaltung:parser}
Der \eng{Parser} parst zum einen die Konfigurationsparameter aus dem \eng{Standard Input} und zum anderen die Ziel-IP-Adressen. 
%Um möglichst performant und ressourcensparend vorzugehen, wird im Allgemein ein Fokus auf die Vermeidung neuer 
%Allokationen und die Daten, falls möglich, mit \eng{Zero-Copy}-Operationen zu verarbeiten.
%Deshalb geschieht das Entgegennehmen, Deserialisieren und Weiterleiten der Adressen in \eng{Batches}.
%Dies minimiert unter anderem die Anzahl der \eng{Context Switches} durch die Reduzierung von \eng{System Calls}. 
Das \eng{Parsing} der im Binärformat übertragenen Daten erfolgt unter Berücksichtigung verschiedener Optimierungsmaßnahmen. 
So wird ein asynchroner \texttt{tokio}-Reader eingesetzt, um zu gewährleisten, dass der Einleseprozess auch bei ausgelasteten 
Kommunikationskanälen andere Programmteile nicht blockiert. Gemäß den in \cref{impl:performance_steigernde_maßnahmen} definierten 
Prinzipien werden zudem \eng{Batching} und \eng{Zero-Copy}-Techniken angewandt (vgl. Codeauszug \ref{lst:parser_binary}). 
Letzteres wird unter anderem durch die Nutzung von \texttt{std::mem::replace} realisiert, womit Speicherpuffer effizient 
durch den Austausch von \eng{Ownership} verwaltet werden. Dies ersetzt kostenintensive Kopieroperationen. 
%Um auch bei fragmentierten Datenübertragungen keine Informationen zu verlieren, 
%wird ein \eng{Offset}-basierter Ansatz verfolgt, der unvollständige IP-Adressen am Ende eines \eng{Batch}-Puffers in den nächsten
%Zyklus überträgt.

%Der folgende \cref{lst:parser_binary} zeigt das \eng{Parsing} der Daten welche im Binärformat übertragen wurden. 
%Um das Verarbeiten unvollständiger IP-Adressen zu vermeiden, wird sich nach jeder Iteration ein \eng{Offset} gemerkt,
%sodass keine Daten verloren gehen, falls ein \eng{Batch} nicht vollständig gefüllt oder sauber am Ende einer Adresse endet. 
%
\begin{lstlisting}[caption={Binärformat-\eng{Parsing} im \eng{Standard-Input} \eng{Parser}},label=lst:parser_binary]
/* Weiterer Code */
// feste Kapazitaet
let mut ip_batch: Vec<[u8; 4]> = Vec::with_capacity(BATCH_SIZE / 4);

loop {
    let read_len = reader.read(&mut buffer[offset..]).await?;
    /* Weiterer Code */
    
    // Verarbeite vollstaendige IP-Pakete
    while cursor + 4 <= valid_data_len {
        let bytes: [u8; 4] = buffer[cursor..cursor + 4].try_into().unwrap();
        cursor += 4;
        if bytes == [0, 0, 0, 0] { /* Terminator -> return */ }
        ip_batch.push(bytes);
    }
    
    // Sende akkumulierten Batch
    if !ip_batch.is_empty() {
        let batch = std::mem::replace(&mut ip_batch, Vec::with_capacity(BATCH_SIZE / 4));
        sender.send(batch).await?;
    }

    /* Weiterer Code */
\end{lstlisting}
%    // Kopiere fragmentierte Bytes an Puffer-Anfang
%    let remaining = valid_data_len - cursor;
%    if remaining > 0 {
%        buffer.copy_within(cursor..valid_data_len, 0);
%    }
%    offset = remaining;
%}
%
%Im bereitgestellten Codeauszug wurden explizit die in \cref{tab:parser-optimizations} beschriebenen Performanz-steigernden Maßnahmen umgesetzt.
%
%\begin{table}[htbp]
%\begin{tabularx}{\textwidth}{|c|X|}\hline 
%\textbf{Maßnahme} & \textbf{Beschreibung} \\ \hline
%\texttt{Vec::with\_capacity()} & Der IP-Puffer wird in einen Puffer mit fester Größe gelesen, welcher somit nur einmal allokiert werden muss. \\ \hline
%\texttt{std::mem::replace} & Ermöglicht das Tauschen des \texttt{ip\_batch}-Puffers gegen einen neu erstellten, leeren Puffer, ohne dass die Inhalte kopiert werden müssen, da lediglich die \eng{Ownership} gewechselt wird. \\ \hline
%Asynchroner \texttt{tokio}-\eng{Reader} & Die Nutzung des asynchronen \texttt{tokio}-\eng{Readers} ermöglicht, dass auch bei vollem \eng{Channel} der \eng{Parser} nie andere Prozesse blockiert. \\ \hline
%\end{tabularx}
%\caption{Performanz-steigernde Maßnahmen im \eng{Standard-Input} \eng{Parser}}
%\label{tab:parser-optimizations}
%\end{table}

\subsubsection{\eng{Scanjob} (\texttt{scanjob.rs})}

Ein \eng{Scanjob} fungiert als zentrale Orchestrierungseinheit für alle \eng{User-Space}-Komponenten des SYN-Scans. Wie in \cref{fig:scanjob_sequence_diag} dargestellt, 
beginnt der Ablauf mit der Initialisierung der \texttt{tokio} \eng{Channels}, um die spätere Vernetzung der Komponenten zu gewährleisten. Anschließend werden die einzelnen 
Module nacheinander als asynchrone \texttt{tokio}-Tasks gestartet: Zunächst der \texttt{parser\_std\_in}, gefolgt von \eng{Receiver} 
und \eng{Sender}. Danach wird der \eng{Rate Limiter} gestartet, woraufhin der \eng{Scanjob} in einen Wartezustand übergeht, bis alle Subsysteme 
ihre Arbeit durch entsprechende Signale als beendet melden.

Da das Anheften eines neuen \texttt{XDP}-Programmes einen Neustart des Netzwerkkartentreibers erfordert, wird vor der Erstellung der Sende-\eng{Sockets} eine kurze Zeit 
gewartet. Auch nach dem Starten des \eng{Senders} und des \eng{Receivers} wird kurz gewartet, damit alles auf Abruf ist,
sobald der \eng{Rate Limiter} mit der Produktion der \texttt{SYN}-Pakete beginnt. Dies dient der allgemeinen Stabilität des Programmes.
Wie bereits in den meisten anderen Komponenten wird auch hier \texttt{tokio} zur nebenläufigen Ausführung der verschiedenen Programmteile genutzt. Dies 
ermöglicht das unabhängige Handeln der einzelnen Bestandteile, was einerseits der Notwendigkeit des gleichzeitigen Sendens und Empfangens entspringt
und andererseits der \eng{Performance}-Steigerung durch Einsparung von Wartezeiten dient.

\section{\texttt{eBPF}} \label{eBPF}
Der \texttt{eBPF} dient dem Scanner als Empfangspunkt für eingehende Pakete und realisiert die Anforderung an moderne Kernel-Mechanismen (siehe \cref{req:NF-03}). Je nachdem in welchem \texttt{XDP}-Modus das Programm ausgeführt wird, agiert dieses direkt 
im Treiber der Netzwerkkarte oder an der ersten Stelle nach Erstellung eines Puffers im Netzwerkstack. Dadurch können die
Pakete bereits am frühestmöglichen Punkt evaluiert, deren relevante Daten extrahiert und direkt ohne Umweg über den geteilten Speicher der \texttt{eBPF-Maps} 
in das \eng{User-Space}-Programm übertragen werden (siehe \cref{fig:kernel_diag}). 
Dies führt zu einer massiven Ressourceneinsparung und das wiederum zu einer Zeiteinsparung, da etliche
Zwischenschritte, welche normalerweise durchlaufen werden müssten, um das Paket durch den Netzwerkstack zum \eng{User-Space} zu leiten und das Wiederversenden
ohne Kopieraufwand oder \eng{Context Switches} passiert. Über die \texttt{XDP\_TX}-Funktion werden \texttt{RST}-Pakete direkt im \texttt{eBPF}-Programm erstellt und wieder verschickt,
sodass der Netzwerkstack sowie \eng{User-Space} komplett vermieden werden.  

\subsection{\texttt{XDP}-Programm} \label{ebpf:xdp_program}
Die Integration des \texttt{eBPF}-Programms in den Kernel-\eng{Hook} erfordert die Kompilierung in das \eng{ELF}-Format. 
Diese Aufgabe, inklusive dem Laden des Programms und der Verwaltung der \texttt{eBPF Maps} (siehe \cref{tab:ebpf_maps}), 
wird durch das \texttt{aya}-\eng{Crate} abstrahiert und vereinfacht. Die Bindung an das Netzwerkinterface erfolgt in der 
\texttt{main.rs}.

\begin{table}[htbp]
\begin{tabularx}{\textwidth}{|c|c|X|}\hline 
\textbf{Name} & \textbf{Typ} & \textbf{Nutzung} \\ \hline
\texttt{STATS} & \texttt{PerCpuArray<u64>} & Effiziente, lockfreie Protokollierung von Statistiken pro CPU \cite{Map_Type_“BPF_MAP_TYPE_PERCPU_ARRAY”_-_eBPF_Docs}\\ \hline
\texttt{WHITELIST\_IPV4} & \texttt{HashMap<[u8; 4], u8>} & \eng{HashMap} zum Abgleich der für den Scan genutzten Quell-IP-Adressen \\ \hline
\texttt{EVENTS} & \texttt{RingBuf} & Effizienter, geteilter Puffer-Ring \cite{Map_Type_“BPF_MAP_TYPE_RINGBUF”_-_eBPF_Docs} zur Übermittlung der extrahierten Zielinformationen valider Pakete an den \eng{Receiver} \\ \hline
\texttt{SIPHASH\_KEY} & \texttt{Array<u64>} & Schlüssel zur korrekten Auswertung des \texttt{SYN}-Cookies \\ \hline
\end{tabularx}
\caption{Genutzte \texttt{eBPF Maps}}
\label{tab:ebpf_maps}
\end{table}


\subsection{Funktionsweise}

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\textwidth]{pictures/ebpf_component_nr.drawio.pdf}
	\caption{Funktionsweise des \texttt{eBPF}-Programmes (vereinfacht)}
	\label{fig:ebpf_component_diag}
\end{figure}

Das \texttt{eBPF}-Programm (siehe \cref{fig:ebpf_component_diag}) extrahiert und validiert initial die Ethernet-, IP- und TCP-Header 
aller eingehenden Pakete. Pakete, die kein valides \eng{IPv4}-\texttt{SYN-ACK} darstellen oder deren \texttt{SYN}-Cookie-Prüfung 
(mittels \eng{SipHash}), beziehungsweise der Abgleich mit der Quell-IP-Whitelist (\texttt{WHITELIST\_IPV4}) fehlschlägt, werden 
unverändert mittels \texttt{XDP\_PASS} an den regulären Netzwerkstack übergeben. 
Dies gewährleistet, dass der Standard-Netzwerkverkehr unbeeinträchtigt bleibt, während valide Antworten gemäß \cref{req:F-05} 
weiterverarbeitet werden.

Die Programmierung im Kernel-Kontext unterliegt strikten Restriktionen (vgl. \cref{Grundlagen.eBPF}). 
Da weder Systemaufrufe noch eine Speicherverwaltung verfügbar sind \cite[S.~59, 206]{Rice_2023}, kommen dynamische Datenstrukturen 
nicht in Frage. Zur typsicheren Verarbeitung ohne Kopieroperationen wird daher das \texttt{network\_types}-\eng{Crate} eingesetzt, 
welches rohe Speicherbereiche direkt auf typisierte Strukturen abbildet. Die Navigation im Speicher erfolgt mittels Zeigerarithmetik 
durch die \texttt{ptr\_at}-Funktion, welche außerdem die Grenzen des Datenbereichs validiert.

\begin{lstlisting}[caption={\texttt{ptr\_at}-Funktion zum Navigieren durch Speicherbereiche},label=lst:ptr_at]
#[inline(always)]
unsafe fn ptr_at<T>(ctx: &XdpContext, offset: usize) -> Result<*const T, ()> {
    let start = ctx.data();
    let end = ctx.data_end();
    let len = mem::size_of::<T>();
    if start + offset + len > end {
        /* Error handling */
    }
    Ok((start + offset) as *const T)
}
\end{lstlisting}

Folgendes Beispiel demonstriert die Extraktion des \eng{IP-Headers} unter Verwendung des Offsets des vorangegangenen 
\eng{Ethernet-Headers} (16 Byte):

\begin{lstlisting}[caption={Extraktion des Speicherbereichs des \eng{IP-Header}},label=lst:ptr_at]
    // IPv4 Header
    let ip: *mut Ipv4Hdr = match unsafe { ptr_at_mut(ctx, EthHdr::LEN) } {
        Ok(p) => p,
        Err(_) => { /* Error handling */ }
    };
\end{lstlisting}

Dabei ist zu beachten, dass diese Speicherzugriffe durch \texttt{unsafe}-Blöcke umschlossen sind. Gemäß \cref{req:NF-04} ist dies zulässig, 
da der direkte Zugriff auf Kernel-Speicher für den angestrebten \eng{Zero-Copy}-Ansatz zwingend notwendig ist. 
Die Standard-Sicherheitsgarantien von Rust basieren üblicherweise auf Laufzeitüberprüfungen (z.B. \eng{Bounds Checks} bei \eng{Slices}), 
die bei Fehlern in einen Programmabbruch (\texttt{panic!}) resultieren. Da ein solcher Abbruch im Kernel-Kontext unzulässig ist 
und das alternative Anlegen einer sicheren Speicherkopie nicht den Performanzzielen dieser Arbeit entsprechen würde, 
wird von den Vorteilen der spezifischen Restriktionen der \texttt{eBPF}-Laufzeitumgebung (vgl. \cref{Grundlagen.eBPF}) Nutzen gezogen. 
Obwohl der \eng{Borrow-Checker} lokal umgangen wird, übernimmt der \texttt{eBPF}-\eng{Verifier} des Linux-Kernels die globale Sicherheitsgarantie. 
Dieser führt bereits zur Ladezeit eine strenge statische Code-Analyse durch und verweigert die Ausführung des Programms, falls 
theoretisch ungültige Speicherzugriffe möglich wären. Somit dient Rust in dieser Architektur primär der Typsicherheit und 
Strukturierung, während der \eng{Verifier} die Rolle der Instanz zur Durchsetzung der Speichersicherheit übernimmt.

Als gültig identifizierte Antworten werden über eine \texttt{PacketLog}-Struktur im \texttt{RingBuf} effizient in den \eng{User-Space} 
übertragen.
Anschließend erfolgt die Modifikation des Pakets zu einem \texttt{RST}-Paket direkt im Speicher (siehe \cref{fig:rst_packet_creation}). 
Durch \eng{In-Place}-Manipulation der \eng{Header}-Felder und Neuberechnung der Prüfsummen wird die Verbindung zum Zielsystem standardkonform 
beendet (\cref{req:F-06}), ohne dass neue Speicherallokationen nötig sind.

\begin{figure}[h]
    \centering
    % Die resizebox sorgt dafür, dass die Grafik exakt die Seitenbreite nutzt
    \resizebox{\textwidth}{!}{%
    \begin{tikzpicture}[
        font=\sffamily\small,
        % Grundstil für die Speicherblöcke
        packetbyte/.style={
            draw, 
            minimum height=1cm, 
            rectangle, 
            align=center, 
            inner sep=4pt,
            outer sep=0pt
        },
        % Farben für die Header
        eth color/.style={fill=blue!10},
        ip color/.style={fill=green!10},
        tcp color/.style={fill=orange!10},
        data color/.style={fill=gray!20},
        % Stil für vertikale Operations-Pfeile (jetzt schwarz)
        op_arrow/.style={
            ->, 
            thick, 
            color=black, % Farbe geändert auf Schwarz
            >=Stealth,
            shorten >=0pt 
        },
        % Stil für Tausch-Pfeile (gebogen, jetzt schwarz)
        swap_arrow/.style={
            <->, 
            thick, 
            color=black, % Farbe geändert auf Schwarz
            >=Stealth,
            shorten >=0pt,
            shorten <=0pt
        },
        % Beschriftungen über Pfeilen
        arrow_label/.style={
            anchor=south, 
            font=\sffamily\footnotesize\bfseries, 
            inner sep=2pt,
            align=center,
            color=black % Textfarbe Schwarz
        }
    ]

        %% --- REIHE 1: ETHERNET HEADER ---
        \node[packetbyte, eth color, minimum width=4cm] (eth_dst) {Dest MAC};
        \node[packetbyte, eth color, minimum width=4cm, right=0cm of eth_dst] (eth_src) {Source MAC};
        \node[packetbyte, eth color, minimum width=3cm, right=0cm of eth_src] (eth_type) {Type};
        \node[right=0.5cm of eth_type, font=\bfseries\large, anchor=west] {Ethernet Header};

        %% --- REIHE 2: IP HEADER ---
        \node[packetbyte, ip color, minimum width=2cm, below=3.5cm of eth_dst.west, anchor=west] (ip_ver) {Ver/HL};
        \node[packetbyte, ip color, minimum width=2cm, right=0cm of ip_ver] (ip_tos) {TOS};
        \node[packetbyte, ip color, minimum width=3cm, right=0cm of ip_tos] (ip_len) {Total Len};
        \node[packetbyte, ip color, minimum width=4cm, right=0cm of ip_len] (ip_rest) {\dots ID/Frag \dots};
        \node[packetbyte, ip color, minimum width=2.5cm, right=0cm of ip_rest] (ip_chk) {Checksum};
        \node[packetbyte, ip color, minimum width=3cm, right=0cm of ip_chk] (ip_src) {Src IP};
        \node[packetbyte, ip color, minimum width=3cm, right=0cm of ip_src] (ip_dst) {Dest IP};
        \node[right=0.5cm of ip_dst, font=\bfseries\large, anchor=west] {IP Header};

        %% --- REIHE 3: TCP HEADER ---
        \node[packetbyte, tcp color, minimum width=3cm, below=3.5cm of ip_ver.west, anchor=west] (tcp_src) {Src Port};
        \node[packetbyte, tcp color, minimum width=3cm, right=0cm of tcp_src] (tcp_dst) {Dest Port};
        \node[packetbyte, tcp color, minimum width=3.5cm, right=0cm of tcp_dst] (tcp_seq) {Seq Num};
        \node[packetbyte, tcp color, minimum width=3.5cm, right=0cm of tcp_seq] (tcp_ack) {Ack Num};
        \node[packetbyte, tcp color, minimum width=2.5cm, right=0cm of tcp_ack] (tcp_flags) {Flags};
        \node[packetbyte, tcp color, minimum width=2.5cm, right=0cm of tcp_flags] (tcp_chk) {Checksum};
        \node[right=0.5cm of tcp_chk, font=\bfseries\large, anchor=west] {TCP Header};

        %% --- REIHE 4: PAYLOAD / OPTIONS ---
        \node[packetbyte, data color, minimum width=18cm, below=3.5cm of tcp_src.west, anchor=west, dashed] (payload) {TCP Options \& Payload};
        \node[right=0.5cm of payload, font=\bfseries\large, text=gray, anchor=west] {Verworfen};

        %% --- OPERATIONEN ---

        % 1. Ethernet Swap
        \draw[swap_arrow] (eth_src.north) to[bend right=45] node[midway, above, font=\bfseries] {Tausche} (eth_dst.north);

        % 2. IP Address Swap
        \draw[swap_arrow] (ip_src.north) to[bend left=60] node[midway, above, font=\bfseries] {Tausche} (ip_dst.north);

        % 3. Set IP Total Length
        \draw[op_arrow] ($(ip_len.north)+(0,0.8)$) node[arrow_label] {Setze 40 Bytes\\(IP + TCP Header)} -- (ip_len.north);

        % 4. Calc IP Checksum
        \draw[op_arrow] ($(ip_chk.north)+(0,0.8)$) node[arrow_label] {Berechne neu} -- (ip_chk.north);

        % 5. Port Swap
        \draw[swap_arrow] (tcp_src.north) to[bend left=60] node[midway, above, font=\bfseries] {Tausche} (tcp_dst.north);

        % 6. Ack -> Seq (Farbe auf Schwarz geändert)
        \draw[->, thick, color=black, >=Stealth] (tcp_ack.north) to[bend right=65] node[midway, above, font=\bfseries\footnotesize] {Kopiere in Seq Num} (tcp_seq.north);

        % 7. Set RST Flag
        \draw[op_arrow] ($(tcp_flags.north)+(0,0.8)$) node[arrow_label] {Setze RST} -- (tcp_flags.north);

        % 8. Calc TCP Checksum
        \draw[op_arrow] ($(tcp_chk.north)+(0,0.8)$) node[arrow_label] {Berechne neu} -- (tcp_chk.north);

        % 9. Visual Cut (Zentriert im nun größeren Abstand)
        \begin{scope}[shift={($(payload.north) + (0, 1.25)$)}] 
            % Pfeil ist nun normal (nicht gestrichelt) und schwarz
            \draw[->, thick, color=black, >=Stealth] (0, 1.0) -- (0, -1.0);
            
            % Das Kreuz (bleibt rot als Highlight)
            \node[scale=0.8, anchor=center] at (0,0) {
                \tikz{
                    \draw[ultra thick] (-0.3,0.3) -- (0.3,-0.3);
                    \draw[ultra thick] (-0.3,-0.3) -- (0.3,0.3);
                }
            };
            % Text ist nun schwarz
            \node[color=black, right, font=\bfseries] at (0.4,0) {Abschneiden};
        \end{scope}

    \end{tikzpicture}
    }
    \caption{\eng{In-Memory}-Modifikation des \texttt{SYN-ACK}-Pakets zum \texttt{RST}-Paket}
    \label{fig:rst_packet_creation}
\end{figure}

Das fertige Paket wird anschließend per \texttt{XDP\_TX} direkt in den Puffer der Netzwerkkarte geschrieben und durch die Modifikationen
als gültiges \texttt{RST}-Paket an den Absender der ursprünglichen \texttt{SYN-ACK}-Antwort zurückgeschickt. Dies dient der Erfüllung der Anforderung 
\cref{req:F-06}.
